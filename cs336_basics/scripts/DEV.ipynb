{
   "cells": [
      {
         "cell_type": "markdown",
         "id": "153fa639",
         "metadata": {},
         "source": [
            "## Start"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 44,
         "id": "2da7993a",
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "import pickle\n",
            "import time\n",
            "import random\n",
            "import torch\n",
            "import math\n",
            "\n",
            "\n",
            "import regex as re\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "import torch.nn as nn\n",
            "from typing import Optional\n",
            "from collections.abc import Callable, Iterable\n",
            "\n",
            "from tqdm import tqdm\n",
            "from concurrent.futures import ProcessPoolExecutor\n",
            "from typing import BinaryIO\n",
            "from collections import defaultdict\n",
            "from collections.abc import Iterable, Iterator\n",
            "from einops import rearrange, einsum, repeat\n",
            "\n",
            "\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 45,
         "id": "f8f7a596",
         "metadata": {},
         "outputs": [],
         "source": [
            "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
            "TOKEN = tuple[bytes]\n",
            "PAIR = tuple[bytes, bytes]\n",
            "END_TOKEN = '<|endoftext|>'"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 46,
         "id": "48a575f8",
         "metadata": {},
         "outputs": [],
         "source": [
            "import sys\n",
            "import os\n",
            "# 获取当前 notebook 所在目录的上两级目录（即项目根目录）\n",
            "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
            "# 将项目根目录加入 sys.path\n",
            "if project_root not in sys.path:\n",
            "    sys.path.append(project_root)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "a2f2e7f3",
         "metadata": {},
         "source": [
            "## 1 Assignment Overview"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "f54e287b",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "id": "2a80feac",
         "metadata": {},
         "source": [
            "## 2 Byte-Pair Encoding (BPE) Tokenizer"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "6fcdbb3e",
         "metadata": {},
         "source": [
            "### 2.1 The Unicode Standard"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "id": "c9bf5df8",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[29275, '牛']"
                  ]
               },
               "execution_count": 3,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "[ord('牛'), chr(29275)]"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "a209ddd0",
         "metadata": {},
         "source": [
            "#### Problem (unicode1)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "bb1d9697",
         "metadata": {},
         "source": [
            "##### a"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "45b90bd1",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'\\x00'"
                  ]
               },
               "execution_count": 3,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "chr(0)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "46f463d9",
         "metadata": {},
         "source": [
            "##### b"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "c91f9fdb",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "\u0000\n"
               ]
            }
         ],
         "source": [
            "print(chr(0))"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "01b6078b",
         "metadata": {},
         "source": [
            "##### c"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "id": "96daa256",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'this is a test\\x00string'"
                  ]
               },
               "execution_count": 8,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "\"this is a test\" + chr(0) + \"string\""
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "id": "86647719",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "this is a test\u0000string\n"
               ]
            }
         ],
         "source": [
            "print(\"this is a test\" + chr(0) + \"string\")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "885fe342",
         "metadata": {},
         "source": [
            "### 2.2 Unicode Encodings"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "id": "12077a57",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "b'hello! \\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf!'\n"
               ]
            }
         ],
         "source": [
            "test_string = \"hello! こんにちは!\"\n",
            "utf8_encoded = test_string.encode(\"utf-8\")\n",
            "print(utf8_encoded)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "id": "dc24edd9",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "<class 'bytes'>\n"
               ]
            }
         ],
         "source": [
            "print(type(utf8_encoded))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "id": "7c38939e",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[104,\n",
                     " 101,\n",
                     " 108,\n",
                     " 108,\n",
                     " 111,\n",
                     " 33,\n",
                     " 32,\n",
                     " 227,\n",
                     " 129,\n",
                     " 147,\n",
                     " 227,\n",
                     " 130,\n",
                     " 147,\n",
                     " 227,\n",
                     " 129,\n",
                     " 171,\n",
                     " 227,\n",
                     " 129,\n",
                     " 161,\n",
                     " 227,\n",
                     " 129,\n",
                     " 175,\n",
                     " 33]"
                  ]
               },
               "execution_count": 12,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "list(utf8_encoded)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "id": "3322f2e7",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[13, 23]"
                  ]
               },
               "execution_count": 13,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "[len(test_string),len(utf8_encoded)]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "id": "b6bb20ca",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "hello! こんにちは!\n"
               ]
            }
         ],
         "source": [
            "print(utf8_encoded.decode(\"utf-8\"))"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "0b18de75",
         "metadata": {},
         "source": [
            "#### Problem (unicode2)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "ed709893",
         "metadata": {},
         "source": [
            "##### a"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "faf37160",
         "metadata": {},
         "source": [
            "##### b"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "id": "f8cfb916",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'hello'"
                  ]
               },
               "execution_count": 15,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "def decode_utf8_bytes_to_str_wrong(bytestring: bytes):\n",
            "    return \"\".join([bytes([b]).decode(\"utf-8\") for b in bytestring])\n",
            "decode_utf8_bytes_to_str_wrong(\"hello\".encode(\"utf-8\"))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "id": "35a3b6be",
         "metadata": {},
         "outputs": [
            {
               "ename": "UnicodeDecodeError",
               "evalue": "'utf-8' codec can't decode byte 0xe4 in position 0: unexpected end of data",
               "output_type": "error",
               "traceback": [
                  "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                  "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
                  "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdecode_utf8_bytes_to_str_wrong\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhello, 你好\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
                  "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mdecode_utf8_bytes_to_str_wrong\u001b[39m\u001b[34m(bytestring)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_utf8_bytes_to_str_wrong\u001b[39m(bytestring: \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bytestring])\n",
                  "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xe4 in position 0: unexpected end of data"
               ]
            }
         ],
         "source": [
            "decode_utf8_bytes_to_str_wrong(\"hello, 你好\".encode(\"utf-8\"))"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "8b68518c",
         "metadata": {},
         "source": [
            "##### c"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "id": "5b92654d",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[b'h',\n",
                     " b'e',\n",
                     " b'l',\n",
                     " b'l',\n",
                     " b'o',\n",
                     " b',',\n",
                     " b' ',\n",
                     " b'\\xe4',\n",
                     " b'\\xbd',\n",
                     " b'\\xa0',\n",
                     " b'\\xe5',\n",
                     " b'\\xa5',\n",
                     " b'\\xbd']"
                  ]
               },
               "execution_count": 18,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "sentence = \"hello, 你好\".encode(\"utf-8\")\n",
            "[bytes([b]) for b in sentence]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "id": "2713459a",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'你'"
                  ]
               },
               "execution_count": 24,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "(b'\\xe4\\xbd\\xa0').decode(\"utf-8\")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "259e6159",
         "metadata": {},
         "source": [
            "### 2.3 Subword Tokenization"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "5eb7babd",
         "metadata": {},
         "source": [
            "### 2.4 BPE Tokenizer Training"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 27,
         "id": "1290735e",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "['some', ' text', ' that', ' i', \"'ll\", ' pre', '-', 'tokenize']"
                  ]
               },
               "execution_count": 27,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "re.findall(PAT, \"some text that i'll pre-tokenize\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 28,
         "id": "1de4c71d",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "('BA', 'A')"
                  ]
               },
               "execution_count": 28,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "max([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"ZZ\"), (\"BA\", \"A\")])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 31,
         "id": "1afabb34",
         "metadata": {},
         "outputs": [],
         "source": [
            "test_string = \"\"\"low low low low low lower lower widest widest widest newest newest newest newest newest newest\"\"\""
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 32,
         "id": "6f73644c",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "['low',\n",
                     " ' low',\n",
                     " ' low',\n",
                     " ' low',\n",
                     " ' low',\n",
                     " ' lower',\n",
                     " ' lower',\n",
                     " ' widest',\n",
                     " ' widest',\n",
                     " ' widest',\n",
                     " ' newest',\n",
                     " ' newest',\n",
                     " ' newest',\n",
                     " ' newest',\n",
                     " ' newest',\n",
                     " ' newest']"
                  ]
               },
               "execution_count": 32,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "re.findall(PAT, test_string)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "30f545de",
         "metadata": {},
         "source": [
            "### 2.5 Experimenting with BPE Tokenizer Training"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "id": "5143d682",
         "metadata": {},
         "outputs": [],
         "source": [
            "def find_chunk_boundaries(\n",
            "    file: BinaryIO,\n",
            "    desired_num_chunks: int,\n",
            "    split_special_token: bytes,\n",
            ") -> list[int]:\n",
            "    \"\"\"\n",
            "    Chunk the file into parts that can be counted independently.\n",
            "    May return fewer chunks if the boundaries end up overlapping.\n",
            "    \"\"\"\n",
            "    assert isinstance(split_special_token, bytes), \"Must represent special token as a bytestring\"\n",
            "\n",
            "    # Get total file size in bytes\n",
            "    file.seek(0, os.SEEK_END)\n",
            "    file_size = file.tell()\n",
            "    file.seek(0)\n",
            "\n",
            "    chunk_size = file_size // desired_num_chunks\n",
            "\n",
            "    # Initial guesses for chunk boundary locations, uniformly spaced\n",
            "    # Chunks start on previous index, don't include last index\n",
            "    chunk_boundaries = [i * chunk_size for i in range(desired_num_chunks + 1)]\n",
            "    chunk_boundaries[-1] = file_size\n",
            "\n",
            "    mini_chunk_size = 4096  # Read ahead by 4k bytes at a time\n",
            "\n",
            "    for bi in range(1, len(chunk_boundaries) - 1):\n",
            "        initial_position = chunk_boundaries[bi]\n",
            "        file.seek(initial_position)  # Start at boundary guess\n",
            "        while True:\n",
            "            mini_chunk = file.read(mini_chunk_size)  # Read a mini chunk\n",
            "\n",
            "            # If EOF, this boundary should be at the end of the file\n",
            "            if mini_chunk == b\"\":\n",
            "                chunk_boundaries[bi] = file_size\n",
            "                break\n",
            "\n",
            "            # Find the special token in the mini chunk\n",
            "            found_at = mini_chunk.find(split_special_token)\n",
            "            if found_at != -1:\n",
            "                chunk_boundaries[bi] = initial_position + found_at\n",
            "                break\n",
            "            initial_position += mini_chunk_size\n",
            "\n",
            "    # Make sure all boundaries are unique, but might be fewer than desired_num_chunks\n",
            "    return sorted(set(chunk_boundaries))\n",
            "\n",
            "def update_token_freqs(\n",
            "    token_freqs: dict[TOKEN, int],\n",
            "    text_segment: str,\n",
            "):\n",
            "    matches = re.finditer(PAT, text_segment)\n",
            "    for m in matches:\n",
            "        token = m.group()\n",
            "        token_bytes = tuple(bytes([b]) for b in token.encode(\"utf-8\"))\n",
            "        token_freqs[token_bytes] += 1 \n",
            "\n",
            "def process_chunk(args):\n",
            "    input_path, start, end, special_tokens, chunk_id = args\n",
            "    # Read chunk\n",
            "    with open(input_path, 'rb') as f:\n",
            "        f.seek(start)\n",
            "        chunk_bytes = f.read(end - start)\n",
            "    \n",
            "    # Decode\n",
            "    chunk_str = chunk_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
            "    \n",
            "    # Logic from original train_bpe\n",
            "    special_pat = \"|\".join(re.escape(st) for st in special_tokens)\n",
            "    segments = re.split(special_pat, chunk_str)\n",
            "    \n",
            "    token_freqs = defaultdict(int)\n",
            "    # Use position=chunk_id+1 so 0 is left for the main bar\n",
            "    for seg in segments:\n",
            "        update_token_freqs(token_freqs, seg)\n",
            "    \n",
            "    return token_freqs\n",
            "\n",
            "def get_pairs(\n",
            "    token: TOKEN\n",
            ") -> list[PAIR]:\n",
            "    if len(token) < 2:\n",
            "        return []\n",
            "    return [(token[i], token[i+1]) for i in range(len(token)-1)]\n",
            "\n",
            "def update_pair_freqs(\n",
            "    pair_freqs: dict[PAIR, int],\n",
            "    token_freqs: dict[TOKEN, int],\n",
            "):\n",
            "    for token, freq in token_freqs.items():\n",
            "        if len(token) < 2:\n",
            "            continue\n",
            "        pairs = get_pairs(token)\n",
            "        for p in pairs:\n",
            "            pair_freqs[p] += freq\n",
            "\n",
            "def update_pair2idx(\n",
            "    pair_to_idx: dict[PAIR, set[TOKEN]],\n",
            "    token_freqs: dict[TOKEN, int],\n",
            "    token_to_idx: dict[TOKEN, int],\n",
            "):\n",
            "    for token, freq in token_freqs.items():\n",
            "        if len(token) < 2:\n",
            "            continue\n",
            "        pairs = get_pairs(token)\n",
            "        for p in pairs:\n",
            "            pair_to_idx[p].add(token_to_idx[token])\n",
            "\n",
            "\n",
            "def get_most_frequent_pair(\n",
            "    pair_freqs: dict[PAIR, int],\n",
            ") -> PAIR:\n",
            "    return max(pair_freqs.keys(), key=lambda k: (pair_freqs[k], k))\n",
            "\n",
            "def update_vocab(\n",
            "    vocab: dict[int, bytes],\n",
            "    new_id: int,\n",
            "    best_pair: PAIR,\n",
            "):\n",
            "    new_vocab = best_pair[0] + best_pair[1]\n",
            "    vocab[new_id] = new_vocab\n",
            "\n",
            "def update_vocab_inverse(\n",
            "    vocab_inverse: dict[bytes, int],\n",
            "    new_id: int,\n",
            "    best_pair: PAIR,\n",
            "):\n",
            "    new_vocab = best_pair[0] + best_pair[1]\n",
            "    vocab_inverse[new_vocab] = new_id\n",
            "\n",
            "def update_merges(\n",
            "    merges: list[PAIR],\n",
            "    best_pair: PAIR,\n",
            "):\n",
            "    merges.append(best_pair)\n",
            "\n",
            "def update_all(\n",
            "    pair_to_idx: dict[PAIR, set[int]],\n",
            "    pair_freqs: dict[PAIR, int],\n",
            "    token_freqs: dict[TOKEN, int],\n",
            "    idx_to_token: dict[int, TOKEN],\n",
            "    best_pair: PAIR,\n",
            "):\n",
            "    affected_idxs = list(pair_to_idx[best_pair])\n",
            "    merged_bytes = best_pair[0] + best_pair[1]\n",
            "\n",
            "    for idx in affected_idxs:\n",
            "        # get new token\n",
            "        i=0\n",
            "        token = idx_to_token[idx]\n",
            "        new_token = []\n",
            "        while(i<(len(token))):\n",
            "            if (i < len(token) - 1) and (token[i] == best_pair[0]) and (token[i+1] == best_pair[1]):\n",
            "                new_token.append(merged_bytes)\n",
            "                i = i + 2\n",
            "            else:\n",
            "                new_token.append(token[i])\n",
            "                i = i + 1\n",
            "        new_token = tuple(new_token)\n",
            "\n",
            "\n",
            "        ## update pair_to_idx\n",
            "        new_pairs = get_pairs(new_token)\n",
            "        affected_pairs = get_pairs(token)\n",
            "        for p in set(new_pairs)-set(affected_pairs):\n",
            "            pair_to_idx[p].add(idx)\n",
            "        for p in set(affected_pairs)-set(new_pairs):\n",
            "            pair_to_idx[p].discard(idx)\n",
            "\n",
            "\n",
            "        ## update pair_freqs\n",
            "        for pair in affected_pairs:\n",
            "            pair_freqs[pair] -= token_freqs[token]\n",
            "        for pair in new_pairs:\n",
            "            pair_freqs[pair] += token_freqs[token]\n",
            "\n",
            "\n",
            "        ## update token_freqs\n",
            "        origin_freq = token_freqs.pop(token)\n",
            "        token_freqs[new_token] = origin_freq\n",
            "\n",
            "        ## update idx_to_token\n",
            "        idx_to_token[idx] = new_token\n",
            "        \n",
            "\n",
            "def train_bpe(\n",
            "    input_path: str,\n",
            "    vocab_size: int,\n",
            "    special_tokens: list[str],\n",
            "    num_processes: int = 4\n",
            "):\n",
            "    print(\"Start Training BPE...\")\n",
            "    start_total = time.time()\n",
            "\n",
            "    print(\"Initialize Vocab and Merges...\")\n",
            "    vocab = {i:bytes([i]) for i in range(256)}\n",
            "    vocab_inverse = {v:k for k,v in vocab.items()}\n",
            "    # Add special tokens\n",
            "    for st in special_tokens:\n",
            "        new_id = len(vocab)\n",
            "        st_bytes = st.encode(\"utf-8\")\n",
            "        vocab[new_id] = st_bytes\n",
            "        vocab_inverse[st_bytes] = new_id\n",
            "    \n",
            "    merges = []\n",
            "\n",
            "    print(\"Calculating chunk boundaries...\")\n",
            "    t0 = time.time()\n",
            "    with open(input_path, 'rb') as f:\n",
            "        # Assuming first special token is the split token\n",
            "        split_token = special_tokens[0].encode(\"utf-8\") if special_tokens else b\"<|endoftext|>\"\n",
            "        boundaries = find_chunk_boundaries(f, num_processes, split_token) # More chunks than processes for load balancing\n",
            "    print(f\"Boundaries calculated in {time.time() - t0:.2f}s\")\n",
            "    \n",
            "    token_freqs = defaultdict(int)\n",
            "\n",
            "    ## Initiate token_freqs\n",
            "    print(\"Update Token Freq (Parallel)...\")\n",
            "    t0 = time.time()\n",
            "    \n",
            "    tasks = []\n",
            "    for i in range(len(boundaries) - 1):\n",
            "        start = boundaries[i]\n",
            "        end = boundaries[i+1]\n",
            "        tasks.append((input_path, start, end, special_tokens, i))\n",
            "    \n",
            "    with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
            "        results = list(tqdm(executor.map(process_chunk, tasks), total=len(tasks), desc=\"Token Freqs (Chunks)\", position=0))\n",
            "        \n",
            "        for local_freqs in results:\n",
            "            for token, count in local_freqs.items():\n",
            "                token_freqs[token] += count\n",
            "                \n",
            "    idx_to_token = {i: k for i, k in enumerate(token_freqs.keys())}\n",
            "    token_to_idx = {k: i for i, k in enumerate(token_freqs.keys())}\n",
            "    print(f\"Update Token Freq took {time.time() - t0:.2f}s\")\n",
            "\n",
            "\n",
            "    ## Initiate pair_freqs, pair_to_token, and token_to_pair\n",
            "    print(\"Update Pair Freq...\")\n",
            "    t0 = time.time()\n",
            "    pair_freqs = defaultdict(int)\n",
            "    update_pair_freqs(pair_freqs, token_freqs)\n",
            "    print(f\"Update Pair Freq took {time.time() - t0:.2f}s\")\n",
            "\n",
            "    print(\"Update Pair to idx...\")\n",
            "    t0 = time.time()\n",
            "    pair_to_idx = defaultdict(set)\n",
            "    update_pair2idx(pair_to_idx, token_freqs, token_to_idx)\n",
            "    print(f\"Update Pair to Token took {time.time() - t0:.2f}s\")\n",
            "\n",
            "    print(\"Start Merging...\")\n",
            "    t0 = time.time()\n",
            "    num_merges = vocab_size - 256 - len(special_tokens)\n",
            "    for i in tqdm(range(num_merges), desc=\"Merging\"):\n",
            "        ### find most frequent pair\n",
            "        if not pair_freqs:\n",
            "            break\n",
            "        best_pair = get_most_frequent_pair(pair_freqs)\n",
            "\n",
            "        new_id = len(vocab)\n",
            "\n",
            "        ## update vocab\n",
            "        update_vocab(vocab, new_id, best_pair)\n",
            "\n",
            "        ## update vocab_inverse\n",
            "        update_vocab_inverse(vocab_inverse, new_id, best_pair)\n",
            "\n",
            "        ## update merges\n",
            "        update_merges(merges, best_pair)\n",
            "\n",
            "        update_all(pair_to_idx, pair_freqs, token_freqs, idx_to_token, best_pair)\n",
            "    print(f\"Merging took {time.time() - t0:.2f}s\")\n",
            "    print(f\"Total Training took {time.time() - start_total:.2f}s\")\n",
            "\n",
            "    return vocab, merges"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "b926ac39",
         "metadata": {},
         "source": [
            "#### Prepare"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "71344ec0",
         "metadata": {},
         "outputs": [],
         "source": [
            "test_string = \"abere ererea<|endoftext|>When and where is not as important as who and what. Hi, I am the the Ivan.<|endoftext|> aaa\"\n",
            "# test_string = \"abere ererea\"\n",
            "input_path = \"\"\n",
            "vocab_size = 260\n",
            "special_tokens = [END_TOKEN]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "id": "80e25f26",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'abere ererea'"
                  ]
               },
               "execution_count": 5,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "special_pat = \"|\".join(re.escape(st) for st in special_tokens)\n",
            "segments = re.split(special_pat, test_string)\n",
            "\n",
            "text_segment = segments[0]\n",
            "text_segment"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "3f0e1451",
         "metadata": {},
         "source": [
            "#### Initialize Vocab and Merges"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "id": "0cf7e249",
         "metadata": {},
         "outputs": [],
         "source": [
            "vocab = {i:bytes([i]) for i in range(256)}\n",
            "vocab_inverse = {v:k for k,v in vocab.items()}\n",
            "# Add special tokens\n",
            "for st in special_tokens:\n",
            "    new_id = len(vocab)\n",
            "    st_bytes = st.encode(\"utf-8\")\n",
            "    vocab[new_id] = st_bytes\n",
            "    vocab_inverse[st_bytes] = new_id\n",
            "\n",
            "merges = []"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "49aceb75",
         "metadata": {},
         "source": [
            "#### Update Token Freq"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "id": "ee804c47",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "defaultdict(int,\n",
                     "            {(b'a', b'b', b'e', b'r', b'e'): 1,\n",
                     "             (b' ', b'e', b'r', b'e', b'r', b'e', b'a'): 1})"
                  ]
               },
               "execution_count": 7,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "token_freqs = defaultdict(int)\n",
            "update_token_freqs(token_freqs,text_segment)\n",
            "token_freqs"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "c3561697",
         "metadata": {},
         "source": [
            "#### Update idx freq"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "id": "2c843b71",
         "metadata": {},
         "outputs": [],
         "source": [
            "idx_to_token = {i: k for i, k in enumerate(token_freqs.keys())}\n",
            "token_to_idx = {k: i for i, k in enumerate(token_freqs.keys())}\n",
            "idx_freqs = {token_to_idx[token]: freq for token, freq in token_freqs.items()}"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "0017256a",
         "metadata": {},
         "source": [
            "#### Update Pair Freq"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "id": "824040e0",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "defaultdict(int,\n",
                     "            {(b'a', b'b'): 1,\n",
                     "             (b'b', b'e'): 1,\n",
                     "             (b'e', b'r'): 3,\n",
                     "             (b'r', b'e'): 3,\n",
                     "             (b' ', b'e'): 1,\n",
                     "             (b'e', b'a'): 1})"
                  ]
               },
               "execution_count": 9,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "pair_freqs = defaultdict(int)\n",
            "update_pair_freqs(pair_freqs,token_freqs)\n",
            "pair_freqs"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "9a8ad346",
         "metadata": {},
         "source": [
            "#### Update Pair to idx"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "id": "892a9535",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "defaultdict(set,\n",
                     "            {(b'a', b'b'): {0},\n",
                     "             (b'b', b'e'): {0},\n",
                     "             (b'e', b'r'): {0, 1},\n",
                     "             (b'r', b'e'): {0, 1},\n",
                     "             (b' ', b'e'): {1},\n",
                     "             (b'e', b'a'): {1}})"
                  ]
               },
               "execution_count": 10,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "pair_to_idx = defaultdict(set)\n",
            "update_pair2idx(pair_to_idx, token_freqs, token_to_idx)\n",
            "pair_to_idx"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "fd9d7008",
         "metadata": {},
         "source": [
            "#### Merging"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "id": "99c45417",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "(b'r', b'e')"
                  ]
               },
               "execution_count": 11,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "best_pair = get_most_frequent_pair(pair_freqs)\n",
            "best_pair"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "id": "6d55fb3b",
         "metadata": {},
         "outputs": [],
         "source": [
            "new_id = len(vocab)\n",
            "\n",
            "## update vocab\n",
            "update_vocab(vocab, new_id, best_pair)\n",
            "\n",
            "## update vocab_inverse\n",
            "update_vocab_inverse(vocab_inverse, new_id, best_pair)\n",
            "\n",
            "## update merges\n",
            "update_merges(merges, best_pair)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "id": "b9a1fc7e",
         "metadata": {},
         "outputs": [],
         "source": [
            "affected_idxs = list(pair_to_idx[best_pair])\n",
            "merged_bytes = best_pair[0] + best_pair[1]\n",
            "for idx in affected_idxs:\n",
            "    token = idx_to_token[idx]\n",
            "\n",
            "    i=0\n",
            "    new_token = []\n",
            "    while(i<(len(token))):\n",
            "        if (i < len(token) - 1) and (token[i] == best_pair[0]) and (token[i+1] == best_pair[1]):\n",
            "            new_token.append(merged_bytes)\n",
            "            i = i + 2\n",
            "        else:\n",
            "            new_token.append(token[i])\n",
            "            i = i + 1\n",
            "    new_token = tuple(new_token)\n",
            "\n",
            "    new_pairs = get_pairs(new_token)\n",
            "    affected_pairs = get_pairs(token)\n",
            "    for p in set(new_pairs)-set(affected_pairs):\n",
            "        pair_to_idx[p].add(idx)\n",
            "    for p in set(affected_pairs)-set(new_pairs):\n",
            "        pair_to_idx[p].discard(idx)\n",
            "\n",
            "\n",
            "    for pair in affected_pairs:\n",
            "        pair_freqs[pair] -= idx_freqs[idx]\n",
            "    for pair in new_pairs:\n",
            "        pair_freqs[pair] += idx_freqs[idx]\n",
            "\n",
            "    # origin_freq = token_freqs.pop(token)\n",
            "    # token_freqs[new_token] = origin_freq\n",
            "\n",
            "    idx_to_token[idx] = new_token"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "id": "6622a581",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "defaultdict(set,\n",
                     "            {(b'a', b'b'): {0},\n",
                     "             (b'b', b'e'): {0},\n",
                     "             (b'e', b'r'): set(),\n",
                     "             (b'r', b'e'): set(),\n",
                     "             (b' ', b'e'): {1},\n",
                     "             (b'e', b'a'): set(),\n",
                     "             (b'e', b're'): {0, 1},\n",
                     "             (b're', b'a'): {1},\n",
                     "             (b're', b're'): {1}})"
                  ]
               },
               "execution_count": 18,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "pair_to_idx"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "id": "1c8bc38a",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "defaultdict(int,\n",
                     "            {(b'a', b'b'): 1,\n",
                     "             (b'b', b'e'): 1,\n",
                     "             (b'e', b'r'): 0,\n",
                     "             (b'r', b'e'): 0,\n",
                     "             (b' ', b'e'): 1,\n",
                     "             (b'e', b'a'): 0,\n",
                     "             (b'e', b're'): 2,\n",
                     "             (b're', b're'): 1,\n",
                     "             (b're', b'a'): 1})"
                  ]
               },
               "execution_count": 19,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "pair_freqs"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 86,
         "id": "a4f47552",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "{0: 1, 1: 1}"
                  ]
               },
               "execution_count": 86,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "idx_freqs"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 46,
         "id": "bcb800c0",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "{0: (b'a', b'b', b'e', b're'), 1: (b' ', b'e', b're', b're', b'a')}"
                  ]
               },
               "execution_count": 46,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "idx_to_token"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "ca3e2ea9",
         "metadata": {},
         "source": [
            "### 2.6 BPE Tokenizer: Encoding and Decoding"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "1c3506f3",
         "metadata": {},
         "source": [
            "##### 2.6.1 Encoding text"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "8ac9f7ff",
         "metadata": {},
         "source": [
            "##### 2.6.2 Decoding text"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "c2a85b24",
         "metadata": {},
         "outputs": [],
         "source": [
            "class Tokenizer():\n",
            "    def __init__(\n",
            "        self, \n",
            "        vocab: dict[int, bytes], \n",
            "        merges: list[PAIR],\n",
            "        special_tokens: list[str] | None = None,\n",
            "    ):\n",
            "        self.vocab = vocab\n",
            "        self.merges = merges\n",
            "        \n",
            "        if special_tokens:\n",
            "            new_index = len(vocab)\n",
            "            for st in special_tokens:\n",
            "                if st != END_TOKEN:\n",
            "                    vocab[new_index] = st\n",
            "                    new_index += 1\n",
            "            self.special_tokens =  sorted(list(set([END_TOKEN]+special_tokens)), key=len, reverse=True)\n",
            "        else:\n",
            "            self.special_tokens = [END_TOKEN]\n",
            "\n",
            "        self.vocab_inverse = {v: k for k, v in vocab.items()}\n",
            "        self.merges_to_rank = {m: i for i, m in enumerate(merges)}\n",
            "\n",
            "    @classmethod\n",
            "    def from_files(\n",
            "        cls, \n",
            "        vocab_filepath: str, \n",
            "        merges_filepath: str, \n",
            "        special_tokens: list[str] | None = None,\n",
            "    ) :\n",
            "        with open(vocab_filepath, \"rb\") as f:\n",
            "            vocab = pickle.load(f)\n",
            "        with open(merges_filepath, \"rb\") as f:\n",
            "            merges = pickle.load(f)\n",
            "        return cls(vocab, merges, special_tokens=special_tokens)\n",
            "\n",
            "    def merge_tokens(self, token_bytes: list[bytes]) -> list[bytes]:\n",
            "        if len(token_bytes) <= 1:\n",
            "            return token_bytes\n",
            "        if token_bytes in self.special_tokens:\n",
            "            return token_bytes\n",
            "        while 1:\n",
            "            merge_position = -1\n",
            "            smallest_rank = len(self.merges)\n",
            "            for i in range(len(token_bytes)-1):\n",
            "                current_pair = (token_bytes[i], token_bytes[i+1])\n",
            "                rank = self.merges_to_rank.get(current_pair, -1)\n",
            "                if rank == -1:\n",
            "                    continue\n",
            "                if rank < smallest_rank:\n",
            "                    smallest_rank = rank\n",
            "                    merge_position = i\n",
            "            if merge_position == -1:\n",
            "                break\n",
            "            token_bytes = token_bytes[:(merge_position)] + [token_bytes[merge_position]+token_bytes[merge_position+1]]+token_bytes[(merge_position+2):]\n",
            "        return token_bytes\n",
            "\n",
            "    def encode(self, text: str) -> list[int]:\n",
            "        special_pat = \"(\"+\"|\".join(re.escape(st) for st in self.special_tokens)+\")\"\n",
            "        segments = re.split(special_pat, text)\n",
            "        ids = []\n",
            "        for segment in segments:\n",
            "            if not segment:\n",
            "                continue\n",
            "            if segment in self.special_tokens:\n",
            "                token_bytes = self.transfer_text2bytes(segment)\n",
            "                token_bytes = self.merge_tokens(token_bytes)\n",
            "                encoded_token = []\n",
            "                for i in token_bytes:\n",
            "                    encoded_token.append(self.vocab_inverse[i])\n",
            "                ids.extend(encoded_token)\n",
            "                continue\n",
            "            matches = re.finditer(PAT, segment)\n",
            "            for m in matches:\n",
            "                token = m.group()\n",
            "                token_bytes = self.transfer_text2bytes(token)\n",
            "                token_bytes = self.merge_tokens(token_bytes)\n",
            "                encoded_token = []\n",
            "                for i in token_bytes:\n",
            "                    encoded_token.append(self.vocab_inverse[i])\n",
            "                ids.extend(encoded_token)\n",
            "        return ids\n",
            "\n",
            "    def _encode_batch(self, texts: list[str]) -> list[list[int]]:\n",
            "        return [self.encode(text) for text in texts]\n",
            "\n",
            "    def encode_iterable(self, iterable: Iterable[str], num_processes: int = 4, batch_size: int = 1000) -> Iterator[int]:\n",
            "        with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
            "            def batch_generator():\n",
            "                current_batch = []\n",
            "                for text in iterable:\n",
            "                    current_batch.append(text)\n",
            "                    if len(current_batch) >= batch_size:\n",
            "                        yield current_batch\n",
            "                        current_batch = []\n",
            "                if current_batch:\n",
            "                    yield current_batch\n",
            "            # 直接在 encode_iterable 这一层产出结果\n",
            "            for batch_results in executor.map(self._encode_batch, batch_generator()):\n",
            "                for seq in batch_results:\n",
            "                    yield from seq\n",
            "\n",
            "    def decode(self, ids: list[int]) -> str:\n",
            "        unk_bytes = '\\ufffd'.encode('utf-8')\n",
            "        bytes_list = [self.vocab.get(i, unk_bytes) for i in ids]\n",
            "        return b\"\".join(bytes_list).decode(\"utf-8\", errors=\"replace\")\n",
            "\n",
            "    def transfer_text2bytes(self, segment: str) -> list[bytes]:\n",
            "        if segment in self.special_tokens:\n",
            "            return [segment.encode(\"utf-8\")]\n",
            "        token_bytes = list(bytes([b]) for b in segment.encode(\"utf-8\"))\n",
            "        return token_bytes"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "id": "ff49ad7c",
         "metadata": {},
         "outputs": [],
         "source": [
            "import tiktoken\n",
            "from tests.adapters import get_tokenizer\n",
            "from tests.common import FIXTURES_PATH, gpt2_bytes_to_unicode\n",
            "\n",
            "VOCAB_PATH = FIXTURES_PATH / \"gpt2_vocab.json\"\n",
            "MERGES_PATH = FIXTURES_PATH / \"gpt2_merges.txt\"\n",
            "\n",
            "from tests.test_tokenizer import get_tokenizer_from_vocab_merges_path"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "25bd8bdf",
         "metadata": {},
         "source": [
            "### 2.7 Experiments"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "id": "ac03fcb4",
         "metadata": {},
         "outputs": [],
         "source": [
            "from cs336_basics.bpe_tokenize import Tokenizer,find_chunk_boundaries,END_TOKEN"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "8e4ba93e",
         "metadata": {},
         "outputs": [],
         "source": [
            "input_path = f\"{project_root}/data/TinyStoriesV2-GPT4-valid.txt\"\n",
            "special_tokens = [END_TOKEN]\n",
            "\n",
            "data_group = \"train\"\n",
            "vocab_size = 10000\n",
            "file_name = f\"TinyStoriesV2-GPT4-{data_group}.txt\"\n",
            "vocab_filepath = f\"{project_root}/outputs/{file_name.split(\".\")[0]}-vocab-{vocab_size}.pkl\"\n",
            "merges_filepath = f\"{project_root}/outputs/{file_name.split(\".\")[0]}-merge-{vocab_size}.pkl\"\n",
            "\n",
            "\n",
            "num_processes = 16\n",
            "\n",
            "\n",
            "tokenizer = Tokenizer.from_files(vocab_filepath,merges_filepath,special_tokens)\n",
            "\n",
            "with open(input_path, 'rb') as f:\n",
            "    split_token = special_tokens[0].encode(\"utf-8\") if special_tokens else b\"\"\n",
            "    boundaries = find_chunk_boundaries(f, num_processes, split_token) \n",
            "\n",
            "start = boundaries[0]\n",
            "end = boundaries[1]\n",
            "\n",
            "with open(input_path, 'rb') as f:\n",
            "    f.seek(start)\n",
            "    chunk_bytes = f.read(end - start)\n",
            "chunk_str = chunk_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
            "special_pat = \"|\".join(re.escape(st) for st in special_tokens)\n",
            "segments = re.split(special_pat, chunk_str)\n",
            "\n",
            "ran_ints = random.sample(range(len(segments)), 10)\n",
            "for i in ran_ints:\n",
            "    ids = tokenizer.encode(segments[i])\n",
            "    print(len(ids)/len(segments[ran_int]))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 43,
         "id": "a09b9de2",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "0.2624356775300172\n",
                  "0.2933104631217839\n",
                  "0.6792452830188679\n",
                  "0.3567753001715266\n",
                  "0.18181818181818182\n",
                  "0.32246998284734135\n",
                  "0.2692967409948542\n",
                  "0.274442538593482\n",
                  "0.3687821612349914\n",
                  "0.2109777015437393\n"
               ]
            }
         ],
         "source": [
            "special_tokens = [END_TOKEN]\n",
            "\n",
            "data_group = \"train\"\n",
            "vocab_size = 10000\n",
            "file_name = f\"TinyStoriesV2-GPT4-{data_group}.txt\"\n",
            "input_path = f\"{project_root}/data/{file_name}\"\n",
            "vocab_filepath = f\"{project_root}/outputs/{file_name.split(\".\")[0]}-vocab-{vocab_size}.pkl\"\n",
            "merges_filepath = f\"{project_root}/outputs/{file_name.split(\".\")[0]}-merge-{vocab_size}.pkl\"\n",
            "\n",
            "\n",
            "num_processes = 16\n",
            "\n",
            "\n",
            "tokenizer = Tokenizer.from_files(vocab_filepath,merges_filepath,special_tokens)\n",
            "\n",
            "with open(input_path, 'rb') as f:\n",
            "    split_token = special_tokens[0].encode(\"utf-8\") if special_tokens else b\"\"\n",
            "    boundaries = find_chunk_boundaries(f, num_processes, split_token) \n",
            "\n",
            "start = boundaries[0]\n",
            "end = boundaries[1]\n",
            "\n",
            "with open(input_path, 'rb') as f:\n",
            "    f.seek(start)\n",
            "    chunk_bytes = f.read(end - start)\n",
            "chunk_str = chunk_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
            "special_pat = \"|\".join(re.escape(st) for st in special_tokens)\n",
            "segments = re.split(special_pat, chunk_str)\n",
            "\n",
            "ran_ints = random.sample(range(len(segments)), 10)\n",
            "for i in ran_ints:\n",
            "    ids = tokenizer.encode(segments[i])\n",
            "    print(len(ids)/len(segments[ran_int]))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 45,
         "id": "554bd4aa",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "1.5901759530791788\n",
                  "0.2631964809384164\n",
                  "0.748533724340176\n",
                  "1.0425219941348973\n",
                  "0.9919354838709677\n",
                  "0.6708211143695014\n",
                  "0.2749266862170088\n",
                  "1.5879765395894427\n",
                  "0.41642228739002934\n",
                  "0.39222873900293254\n"
               ]
            }
         ],
         "source": [
            "special_tokens = [END_TOKEN]\n",
            "\n",
            "data_group = \"train\"\n",
            "vocab_size = 32000\n",
            "file_name = f\"owt_{data_group}.txt\"\n",
            "input_path = f\"{project_root}/data/{file_name}\"\n",
            "vocab_filepath = f\"{project_root}/outputs/{file_name.split(\".\")[0]}-vocab-{vocab_size}.pkl\"\n",
            "merges_filepath = f\"{project_root}/outputs/{file_name.split(\".\")[0]}-merge-{vocab_size}.pkl\"\n",
            "\n",
            "\n",
            "num_processes = 16\n",
            "\n",
            "\n",
            "tokenizer = Tokenizer.from_files(vocab_filepath,merges_filepath,special_tokens)\n",
            "\n",
            "with open(input_path, 'rb') as f:\n",
            "    split_token = special_tokens[0].encode(\"utf-8\") if special_tokens else b\"\"\n",
            "    boundaries = find_chunk_boundaries(f, num_processes, split_token) \n",
            "\n",
            "start = boundaries[0]\n",
            "end = boundaries[1]\n",
            "\n",
            "with open(input_path, 'rb') as f:\n",
            "    f.seek(start)\n",
            "    chunk_bytes = f.read(end - start)\n",
            "chunk_str = chunk_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
            "special_pat = \"|\".join(re.escape(st) for st in special_tokens)\n",
            "segments = re.split(special_pat, chunk_str)\n",
            "\n",
            "ran_ints = random.sample(range(len(segments)), 10)\n",
            "for i in ran_ints:\n",
            "    ids = tokenizer.encode(segments[i])\n",
            "    print(len(ids)/len(segments[ran_int]))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 46,
         "id": "c029c1c3",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "0.2641509433962264\n",
                  "0.27101200686106347\n",
                  "0.3584905660377358\n",
                  "0.3516295025728988\n",
                  "0.3584905660377358\n",
                  "0.3156089193825043\n",
                  "0.8576329331046312\n",
                  "0.5728987993138936\n",
                  "0.27958833619210977\n",
                  "0.4922813036020583\n"
               ]
            }
         ],
         "source": [
            "special_tokens = [END_TOKEN]\n",
            "\n",
            "data_group = \"train\"\n",
            "vocab_size = 32000\n",
            "file_name = f\"owt_{data_group}.txt\"\n",
            "input_path = f\"{project_root}/data/TinyStoriesV2-GPT4-train.txt\"\n",
            "vocab_filepath = f\"{project_root}/outputs/{file_name.split(\".\")[0]}-vocab-{vocab_size}.pkl\"\n",
            "merges_filepath = f\"{project_root}/outputs/{file_name.split(\".\")[0]}-merge-{vocab_size}.pkl\"\n",
            "\n",
            "\n",
            "num_processes = 16\n",
            "\n",
            "\n",
            "tokenizer = Tokenizer.from_files(vocab_filepath,merges_filepath,special_tokens)\n",
            "\n",
            "with open(input_path, 'rb') as f:\n",
            "    split_token = special_tokens[0].encode(\"utf-8\") if special_tokens else b\"\"\n",
            "    boundaries = find_chunk_boundaries(f, num_processes, split_token) \n",
            "\n",
            "start = boundaries[0]\n",
            "end = boundaries[1]\n",
            "\n",
            "with open(input_path, 'rb') as f:\n",
            "    f.seek(start)\n",
            "    chunk_bytes = f.read(end - start)\n",
            "chunk_str = chunk_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
            "special_pat = \"|\".join(re.escape(st) for st in special_tokens)\n",
            "segments = re.split(special_pat, chunk_str)\n",
            "\n",
            "ran_ints = random.sample(range(len(segments)), 10)\n",
            "for i in ran_ints:\n",
            "    ids = tokenizer.encode(segments[i])\n",
            "    print(len(ids)/len(segments[ran_int]))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 31,
         "id": "b60a2e9f",
         "metadata": {},
         "outputs": [],
         "source": [
            "ran_int = ran_ints[0]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 34,
         "id": "a69aa2f4",
         "metadata": {},
         "outputs": [],
         "source": [
            "ids = tokenizer.encode(segments[ran_int])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "10bc4ae2",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "0.24390243902439024"
                  ]
               },
               "execution_count": 35,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": []
      },
      {
         "cell_type": "markdown",
         "id": "9e4bcb86",
         "metadata": {},
         "source": [
            "## 3 Transformer Language Model Architecture"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "968bd4f9",
         "metadata": {},
         "source": [
            "### 3.1 Transformer LM"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "582898d8",
         "metadata": {},
         "source": [
            "#### 3.1.1 Token Embeddings"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "ad60c47a",
         "metadata": {},
         "source": [
            "#### 3.1.2 Pre-norm Transformer Block"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "2929ee06",
         "metadata": {},
         "source": [
            "### 3.2 Output Normalization and Embedding"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "9510b583",
         "metadata": {},
         "source": [
            "### 3.3 Remark: Batching, Einsum and Eﬀicient Computation"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "id": "40645c38",
         "metadata": {},
         "outputs": [],
         "source": [
            "images = torch.randn(64, 128, 128, 3) # (batch, height, width, channel)\n",
            "dim_by = torch.linspace(start=0.0, end=1.0, steps=10)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "id": "530a17d5",
         "metadata": {},
         "outputs": [],
         "source": [
            "dim_value = rearrange(dim_by, \"dim_value -> 1 dim_value 1 1 1\")\n",
            "images_rearr = rearrange(images, \"b height width channel -> b 1 height width channel\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "id": "67743218",
         "metadata": {},
         "outputs": [],
         "source": [
            "dimmed_images = images_rearr * dim_value"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "id": "3438c810",
         "metadata": {},
         "outputs": [],
         "source": [
            "dimmed_images = einsum(\n",
            "    images, dim_by,\n",
            "    \"batch height width channel, dim_value -> batch dim_value height width channel\"\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "id": "688b2df1",
         "metadata": {},
         "outputs": [],
         "source": [
            "channels_last = torch.randn(64, 32, 32, 3) # (batch, height, width, channel)\n",
            "B = torch.randn(32*32, 32*32)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "f8e1bfb1",
         "metadata": {},
         "outputs": [],
         "source": [
            "## Rearrange an image tensor for mixing across all pixels\n",
            "channels_last_flat = channels_last.view(\n",
            "    -1, channels_last.size(1) * channels_last.size(2), channels_last.size(3)\n",
            ")\n",
            "channels_first_flat = channels_last_flat.transpose(1, 2)\n",
            "channels_first_flat_transformed = channels_first_flat @ B.T\n",
            "channels_last_flat_transformed = channels_first_flat_transformed.transpose(1, 2)\n",
            "channels_last_transformed = channels_last_flat_transformed.view(*channels_last.shape)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "id": "cdf7de6f",
         "metadata": {},
         "outputs": [],
         "source": [
            "height = width = 32\n",
            "## Rearrange replaces clunky torch view + transpose\n",
            "channels_first = rearrange(\n",
            "    channels_last,\n",
            "    \"batch height width channel -> batch channel (height width)\"\n",
            ")\n",
            "channels_first_transformed = einsum(\n",
            "    channels_first, B,\n",
            "    \"batch channel pixel_in, pixel_out pixel_in -> batch channel pixel_out\"\n",
            ")\n",
            "channels_last_transformed = rearrange(\n",
            "    channels_first_transformed,\n",
            "    \"batch channel (height width) -> batch height width channel\",\n",
            "    height=height, width=width\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "id": "4b25c164",
         "metadata": {},
         "outputs": [
            {
               "ename": "NameError",
               "evalue": "name 'einx' is not defined",
               "output_type": "error",
               "traceback": [
                  "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                  "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                  "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m height = width = \u001b[32m32\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m channels_last_transformed = \u001b[43meinx\u001b[49m.dot(\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbatch row_in col_in channel, (row_out col_out) (row_in col_in)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m-> batch row_out col_out channel\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     channels_last, B,\n\u001b[32m      6\u001b[39m     col_in=width, col_out=width\n\u001b[32m      7\u001b[39m )\n",
                  "\u001b[31mNameError\u001b[39m: name 'einx' is not defined"
               ]
            }
         ],
         "source": [
            "height = width = 32\n",
            "channels_last_transformed = einx.dot(\n",
            "    \"batch row_in col_in channel, (row_out col_out) (row_in col_in)\"\n",
            "    \"-> batch row_out col_out channel\",\n",
            "    channels_last, B,\n",
            "    col_in=width, col_out=width\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "c4581dc1",
         "metadata": {},
         "source": [
            "#### 3.3.1 Mathematical Notation and Memory Ordering"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "1263a6a4",
         "metadata": {},
         "source": [
            "### 3.4 Basic Building Blocks: Linear and Embedding Modules"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "33dcbaf1",
         "metadata": {},
         "source": [
            "#### 3.4.1 Parameter Initialization"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "fded2dc4",
         "metadata": {},
         "source": [
            "#### 3.4.2 Linear Module"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "3527dc9a",
         "metadata": {},
         "outputs": [],
         "source": [
            "class Linear(nn.Module):\n",
            "    def __init__(\n",
            "        self, \n",
            "        in_features: int, \n",
            "        out_features: int, \n",
            "        device: torch.device | None = None, \n",
            "        dtype: torch.dtype | None = None\n",
            "    ):\n",
            "        super().__init__()\n",
            "        self.in_features = in_features\n",
            "        self.out_features = out_features\n",
            "        self.device = device\n",
            "        self.dtype = dtype\n",
            "\n",
            "        self.weights = nn.Parameter(\n",
            "            torch.empty(out_features, in_features, device=self.device, dtype=self.dtype)\n",
            "        )\n",
            "        std = np.sqrt(2/(in_features+out_features))\n",
            "        nn.init.trunc_normal_(\n",
            "            self.weights,\n",
            "            mean = 0,\n",
            "            std=std,\n",
            "            a=-3*std,\n",
            "            b=3*std\n",
            "        )\n",
            "\n",
            "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
            "        '''\n",
            "        Apply the linear transformation to the input\n",
            "        '''\n",
            "        output = einsum(\n",
            "            x, self.weights,\n",
            "            \"... in_features, out_features in_features -> ... out_features\"\n",
            "        )\n",
            "        return output\n",
            "        "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 26,
         "id": "e8a8e752",
         "metadata": {},
         "outputs": [],
         "source": [
            "in_features = 4\n",
            "out_features = 2"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 31,
         "id": "254160f9",
         "metadata": {},
         "outputs": [],
         "source": [
            "weights = nn.Parameter(\n",
            "            torch.empty(out_features, in_features)\n",
            "        )"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "e881816a",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Parameter containing:\n",
                     "tensor([[-0.3163,  0.2574, -0.6433, -1.2062],\n",
                     "        [-0.2289,  0.3611,  0.4565, -0.2161]], requires_grad=True)"
                  ]
               },
               "execution_count": 35,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "std = np.sqrt(2/(in_features+out_features))\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "d5ed169f",
         "metadata": {},
         "source": [
            "#### 3.4.3 Embedding Module"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "d5dc7d33",
         "metadata": {},
         "outputs": [],
         "source": [
            "class Embedding(nn.Module):\n",
            "    def __init__(\n",
            "        self, \n",
            "        num_embeddings: int, \n",
            "        embedding_dim: int, \n",
            "        device: torch.device | None = None, \n",
            "        dtype: torch.dtype | None = None\n",
            "    ):\n",
            "        super().__init__()\n",
            "        self.num_embeddings = num_embeddings\n",
            "        self.embedding_dim = embedding_dim\n",
            "        self.device = device\n",
            "        self.dtype = dtype\n",
            "\n",
            "        self.weights = nn.Parameter(\n",
            "            torch.empty(num_embeddings, embedding_dim, device=self.device, dtype=self.dtype)\n",
            "        )\n",
            "        nn.init.trunc_normal_(\n",
            "            self.weights,\n",
            "            mean = 0,\n",
            "            std=1,\n",
            "            a=-3,\n",
            "            b=3\n",
            "        )\n",
            "\n",
            "    def forward(self, token_ids: torch.Tensor) -> torch.Tensor:\n",
            "        output = self.weights[token_ids]\n",
            "        return output"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "id": "66e10bca",
         "metadata": {},
         "outputs": [],
         "source": [
            "num_embeddings = 4\n",
            "embedding_dim = 2"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "fac35cde",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Parameter containing:\n",
                     "tensor([[ 1.1913,  0.2204],\n",
                     "        [ 0.8022, -0.8639],\n",
                     "        [-0.1520,  0.4158],\n",
                     "        [ 2.5936,  1.7208]], requires_grad=True)"
                  ]
               },
               "execution_count": 9,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "weights = nn.Parameter(\n",
            "            torch.empty(num_embeddings, embedding_dim)\n",
            "        )\n",
            "nn.init.trunc_normal_(\n",
            "            weights,\n",
            "            mean = 0,\n",
            "            std=1,\n",
            "            a=-3,\n",
            "            b=3\n",
            "        )\n",
            "embedding"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "94653af3",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[ 0.8022, -0.8639],\n",
                     "        [ 2.5936,  1.7208],\n",
                     "        [-0.1520,  0.4158]], grad_fn=<IndexBackward0>)"
                  ]
               },
               "execution_count": 24,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "token_ids = torch.tensor([1,3,2], dtype=torch.int)\n",
            "weights[token_ids]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "9bf600f7",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "id": "c455b7a4",
         "metadata": {},
         "source": [
            "### 3.5 Pre-Norm Transformer Block"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "e065863c",
         "metadata": {},
         "source": [
            "#### 3.5.1 Root Mean Square Layer Normalization"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "dc300853",
         "metadata": {},
         "outputs": [],
         "source": [
            "class RMSNorm(nn.Module):\n",
            "    def __init__(\n",
            "        self, \n",
            "        d_model: int, \n",
            "        eps: float = 1e-5, \n",
            "        device: torch.device | None = None, \n",
            "        dtype: torch.dtype | None = None\n",
            "    ):\n",
            "        super().__init__()\n",
            "        self.d_model = d_model\n",
            "        self.eps = eps\n",
            "        self.device = device\n",
            "        self.dtype = dtype\n",
            "\n",
            "        self.weights = nn.Parameter(\n",
            "            torch.ones(d_model, device=self.device, dtype=self.dtype)\n",
            "        )\n",
            "\n",
            "\n",
            "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
            "        in_dtype = x.dtype\n",
            "        x = x.to(torch.float32)\n",
            "        ms = x.pow(2).mean(dim=-1, keepdim=True)\n",
            "        rms = torch.sqrt(ms+self.eps)\n",
            "        result = x/rms * self.weights\n",
            "        return result.to(in_dtype)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "6802b165",
         "metadata": {},
         "source": [
            "#### 3.5.2 Position-Wise Feed-Forward Network"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "c818d959",
         "metadata": {},
         "outputs": [],
         "source": [
            "class SwiGLU(nn.Module):\n",
            "    def __init__(\n",
            "        self, \n",
            "        d_model: int, \n",
            "        d_ff: int, \n",
            "        device: torch.device | None = None, \n",
            "        dtype: torch.dtype | None = None\n",
            "    ):\n",
            "        super().__init__()\n",
            "        self.d_model = d_model\n",
            "        self.d_ff = d_ff\n",
            "        self.device = device\n",
            "        self.dtype = dtype\n",
            "\n",
            "\n",
            "        self.w1_weight = Linear(self.d_model,self.d_ff,self.device,self.dtype)\n",
            "        self.w2_weight = Linear(self.d_ff,self.d_model,self.device,self.dtype)\n",
            "        self.w3_weight = Linear(self.d_model,self.d_ff,self.device,self.dtype)\n",
            "\n",
            "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
            "        def SiLU(x: torch.Tensor) -> torch.Tensor:\n",
            "            return x*torch.sigmoid(x)\n",
            "        \n",
            "        x1 = self.w1_weight(x)\n",
            "        x1_silu = SiLU(x1)\n",
            "        x3 = self.w3_weight(x)\n",
            "        x1_silu_x3 = x1_silu*x3\n",
            "        result = self.w2_weight(x1_silu_x3)\n",
            "        return result"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "7c1a1d85",
         "metadata": {},
         "source": [
            "#### 3.5.3 Relative Positional Embeddings"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "e7a4c967",
         "metadata": {},
         "outputs": [],
         "source": [
            "class RotaryPositionalEmbedding(nn.Module):\n",
            "    def __init__(\n",
            "        self, \n",
            "        theta: float, \n",
            "        d_k: int, \n",
            "        max_seq_len: int,\n",
            "        device: torch.device | None = None, \n",
            "    ):\n",
            "        super().__init__()\n",
            "        self.theta = theta\n",
            "        self.d_k = d_k\n",
            "        self.max_seq_len = max_seq_len\n",
            "        self.device = device\n",
            "\n",
            "        dim_index = torch.arange(self.d_k // 2, device=self.device, dtype=torch.float32)\n",
            "        position_index = torch.arange(self.max_seq_len, device=self.device, dtype=torch.float32)\n",
            "        theta_inv_index = self.theta**(-2*dim_index/d_k)\n",
            "        theta_ik = einsum(\n",
            "            position_index, theta_inv_index,\n",
            "            \"s, d -> s d\"\n",
            "        )\n",
            "\n",
            "\n",
            "        sin = torch.sin(theta_ik)\n",
            "        cos = torch.cos(theta_ik)\n",
            "        \n",
            "        self.register_buffer(\"sin\", sin, persistent=False)\n",
            "        self.register_buffer(\"cos\", cos, persistent=False)\n",
            "    \n",
            "    def forward(\n",
            "        self, x: torch.Tensor,\n",
            "        toke_position: torch.Tensor,\n",
            "    ) -> torch.Tensor:\n",
            "        x_even = x[...,::2]\n",
            "        x_odd = x[...,1::2]\n",
            "\n",
            "        sin_expend = sin[position]\n",
            "        cos_expend = cos[position]\n",
            "\n",
            "        x_even_new = x_even*cos_expend-x_odd*sin_expend\n",
            "        x_odd_new = x_even*sin_expend+x_odd*cos_expend\n",
            "\n",
            "        x_rope = rearrange(\n",
            "            torch.stack([x_even_new,x_odd_new], dim=-1),\n",
            "            '... seq_len d_k two -> ... seq_len (d_k two)',\n",
            "        )\n",
            "        return x_rope"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 25,
         "id": "1b7ab077",
         "metadata": {},
         "outputs": [],
         "source": [
            "max_seq_len = 5\n",
            "d_k = 4\n",
            "theta = 2\n",
            "device = 'mps'\n",
            "dim_index = torch.arange(d_k // 2)\n",
            "position_index = torch.arange(max_seq_len)\n",
            "theta_inv_index = theta**(-2*dim_index/d_k)\n",
            "theta_ik = einsum(\n",
            "    position_index, theta_inv_index,\n",
            "    \"s, d -> s d\"\n",
            ")\n",
            "\n",
            "\n",
            "sin = torch.sin(theta_ik)\n",
            "cos = torch.cos(theta_ik)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 26,
         "id": "f9c774cf",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[[ 0,  1,  2,  3],\n",
                     "         [ 4,  5,  6,  7],\n",
                     "         [ 8,  9, 10, 11]]])"
                  ]
               },
               "execution_count": 26,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "dim1 = 1\n",
            "seq_len = 3\n",
            "d_k = 4\n",
            "x = torch.arange(dim1*seq_len*d_k).reshape(dim1,seq_len,d_k)\n",
            "position = torch.arange(seq_len).unsqueeze(0).expand(dim1,seq_len)\n",
            "x"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 27,
         "id": "90bd6aea",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[[ 0,  2],\n",
                     "         [ 4,  6],\n",
                     "         [ 8, 10]]])"
                  ]
               },
               "execution_count": 27,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "x_even = x[...,::2]\n",
            "x_odd = x[...,1::2]\n",
            "x_even"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 28,
         "id": "f3e70fde",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[[0.0000, 0.0000],\n",
                     "         [0.8415, 0.6496],\n",
                     "         [0.9093, 0.9878]]])"
                  ]
               },
               "execution_count": 28,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "sin_expend = sin[position]\n",
            "cos_expend = cos[position]\n",
            "sin_expend"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 40,
         "id": "017df81b",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[[  0.0000,   2.0000],\n",
                     "         [ -2.0461,   0.0140],\n",
                     "         [-11.5129,  -9.3060]]])"
                  ]
               },
               "execution_count": 40,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "x_even_new = x_even*cos_expend-x_odd*sin_expend\n",
            "x_odd_new = x_even*sin_expend+x_odd*cos_expend\n",
            "x_even_new"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 41,
         "id": "1341e04c",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[[ 1.0000,  3.0000],\n",
                     "         [ 6.0674,  9.2195],\n",
                     "         [ 3.5291, 11.5930]]])"
                  ]
               },
               "execution_count": 41,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "x_odd_new"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 38,
         "id": "71365828",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[[[  0.0000,   1.0000],\n",
                     "          [  2.0000,   3.0000]],\n",
                     "\n",
                     "         [[ -2.0461,   6.0674],\n",
                     "          [  0.0140,   9.2195]],\n",
                     "\n",
                     "         [[-11.5129,   3.5291],\n",
                     "          [ -9.3060,  11.5930]]]])"
                  ]
               },
               "execution_count": 38,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "temp = torch.stack([x_even_new,x_odd_new], dim=-1)\n",
            "temp"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "9ca15b1d",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[[  0.0000,   2.0000,   1.0000,   3.0000],\n",
                     "         [ -2.0461,   0.0140,   6.0674,   9.2195],\n",
                     "         [-11.5129,  -9.3060,   3.5291,  11.5930]]])"
                  ]
               },
               "execution_count": 43,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "rearrange(\n",
            "    temp,\n",
            "    '... seq_len d_k two -> ... seq_len (d_k two)',\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "0f17e988",
         "metadata": {},
         "source": [
            "#### 3.5.4 Scaled Dot-Product Attention"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "11602a83",
         "metadata": {},
         "source": [
            "##### softmax"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 54,
         "id": "edec4691",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[[ 0,  1,  2],\n",
                     "         [ 3,  4,  5],\n",
                     "         [ 6,  7,  8],\n",
                     "         [ 9, 10, 11]],\n",
                     "\n",
                     "        [[12, 13, 14],\n",
                     "         [15, 16, 17],\n",
                     "         [18, 19, 20],\n",
                     "         [21, 22, 23]]])"
                  ]
               },
               "execution_count": 54,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "dimension = 2\n",
            "dim1 = 2\n",
            "dim2 = 4\n",
            "dim3 = 3\n",
            "x = torch.arange(dim1*dim2*dim3).reshape(dim1,dim2,dim3)\n",
            "x"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 55,
         "id": "bc2492b7",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "torch.Size([2, 4, 1])"
                  ]
               },
               "execution_count": 55,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "values, indices = torch.max(x, dim=dimension, keepdim=True)\n",
            "values.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 56,
         "id": "29d4a8f0",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[[-2, -1,  0],\n",
                     "         [-2, -1,  0],\n",
                     "         [-2, -1,  0],\n",
                     "         [-2, -1,  0]],\n",
                     "\n",
                     "        [[-2, -1,  0],\n",
                     "         [-2, -1,  0],\n",
                     "         [-2, -1,  0],\n",
                     "         [-2, -1,  0]]])"
                  ]
               },
               "execution_count": 56,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "x-values"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 61,
         "id": "e2e7a33b",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[[0.1353, 0.3679, 1.0000],\n",
                     "         [0.1353, 0.3679, 1.0000],\n",
                     "         [0.1353, 0.3679, 1.0000],\n",
                     "         [0.1353, 0.3679, 1.0000]],\n",
                     "\n",
                     "        [[0.1353, 0.3679, 1.0000],\n",
                     "         [0.1353, 0.3679, 1.0000],\n",
                     "         [0.1353, 0.3679, 1.0000],\n",
                     "         [0.1353, 0.3679, 1.0000]]])"
                  ]
               },
               "execution_count": 61,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "x_exp = torch.exp(x-values)\n",
            "x_exp"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 62,
         "id": "5967d390",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[[0.0900, 0.2447, 0.6652],\n",
                     "         [0.0900, 0.2447, 0.6652],\n",
                     "         [0.0900, 0.2447, 0.6652],\n",
                     "         [0.0900, 0.2447, 0.6652]],\n",
                     "\n",
                     "        [[0.0900, 0.2447, 0.6652],\n",
                     "         [0.0900, 0.2447, 0.6652],\n",
                     "         [0.0900, 0.2447, 0.6652],\n",
                     "         [0.0900, 0.2447, 0.6652]]])"
                  ]
               },
               "execution_count": 62,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "x_exp/torch.sum(x_exp, dim=dimension, keepdim=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "7ae4cc72",
         "metadata": {},
         "outputs": [],
         "source": [
            "def softmax(\n",
            "    x: torch.Tensor,\n",
            "    dimension: int,    \n",
            "):\n",
            "    max_values, _ = torch.max(x, dim=dimension, keepdim=True)\n",
            "    x_exp = torch.exp(x-max_values)\n",
            "    x_rxp_sum = torch.sum(x_exp, dim=dimension, keepdim=True)\n",
            "    return x_exp/x_rxp_sum"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "8486826b",
         "metadata": {},
         "source": [
            "##### scaled_dot_product_attention"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 83,
         "id": "43dcf042",
         "metadata": {},
         "outputs": [],
         "source": [
            "from cs336_basics.transformer import softmax"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 102,
         "id": "7a05f252",
         "metadata": {},
         "outputs": [],
         "source": [
            "batch_size = 2\n",
            "dim1 = 1\n",
            "seq_len = 3\n",
            "d_k = 4\n",
            "d_v = 8\n",
            "Q = torch.rand(batch_size*dim1*seq_len*d_k).reshape(batch_size,dim1,seq_len,d_k)\n",
            "K = torch.rand(batch_size*dim1*seq_len*d_k).reshape(batch_size,dim1,seq_len,d_k)\n",
            "V = torch.rand(batch_size*dim1*seq_len*d_v).reshape(batch_size,dim1,seq_len,d_v)\n",
            "mask = (torch.rand(seq_len*seq_len) > 0.5).reshape(seq_len,seq_len)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 103,
         "id": "03d1f9eb",
         "metadata": {},
         "outputs": [],
         "source": [
            "QK= einsum(\n",
            "    Q, K,\n",
            "    \"batch ... seq_n d_k,  batch ... seq_m d_k -> batch ... seq_n seq_m\"\n",
            ")\n",
            "QK_scaled = QK/torch.tensor(d_k).sqrt()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 109,
         "id": "a9d95dc9",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[False, False,  True],\n",
                     "        [ True, False,  True],\n",
                     "        [False, False,  True]])"
                  ]
               },
               "execution_count": 109,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "mask"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 110,
         "id": "fa141b66",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[-inf, -inf, 0.],\n",
                     "        [0., -inf, 0.],\n",
                     "        [-inf, -inf, 0.]])"
                  ]
               },
               "execution_count": 110,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "M = torch.where(mask, torch.tensor(0.0), torch.tensor(float('-inf')))\n",
            "M"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 107,
         "id": "7ff1d627",
         "metadata": {},
         "outputs": [],
         "source": [
            "QK_soft_max = softmax(QK, -1)\n",
            "result = einsum(\n",
            "    QK_soft_max, V,\n",
            "    \"batch ... seq_n seq_m, batch ... seq_n d_v -> batch ... seq_m d_v\"\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "e98a524a",
         "metadata": {},
         "outputs": [],
         "source": [
            "def scaled_dot_product_attention(\n",
            "    Q: torch.Tensor,\n",
            "    K: torch.Tensor,\n",
            "    V: torch.Tensor,\n",
            "    mask: torch.Tensor\n",
            "):\n",
            "    d_k = Q.shape[-1]\n",
            "    QK= einsum(\n",
            "        Q, K,\n",
            "        \"batch ... seq_n d_k,  batch ... seq_m d_k -> batch ... seq_n seq_m\"\n",
            "    )/torch.tensor(Q.shape[-1])\n",
            "    QK_soft_max = softmax(QK, -1)\n",
            "    result = einsum(\n",
            "        QK_soft_max, V,\n",
            "        \"batch ... seq_n seq_m, batch ... seq_n d_v -> batch ... seq_m d_v\"\n",
            "    )\n",
            "    return result"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 97,
         "id": "021b6f5b",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor(4)"
                  ]
               },
               "execution_count": 97,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "torch.tensor(Q.shape[-1])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "220c74c3",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "4"
                  ]
               },
               "execution_count": 100,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "Q.dim()-1"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "c1d4e180",
         "metadata": {},
         "source": [
            "#### 3.5.5 Causal Multi-Head Self-Attention"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "17a95d70",
         "metadata": {},
         "outputs": [],
         "source": [
            "class MultiheadSelfAttention(nn.Module):\n",
            "    def __init__(\n",
            "        self, \n",
            "        d_model: int, \n",
            "        num_heads: int, \n",
            "        theta: float|None=None,\n",
            "        max_seq_len:int|None=None,\n",
            "        device: torch.device | None = None, \n",
            "        dtype: torch.dtype | None = None\n",
            "    ):\n",
            "        super().__init__()\n",
            "        self.d_model = d_model\n",
            "        self.num_heads = num_heads\n",
            "        self.theta = theta\n",
            "        self.max_seq_len = max_seq_len\n",
            "        self.device = device\n",
            "        self.dtype = dtype\n",
            "\n",
            "        self.rope = None\n",
            "        self.d_k = int(d_model/num_heads)\n",
            "        self.d_v = int(d_model/num_heads)\n",
            "\n",
            "        W_Q = Linear(d_model, num_heads*self.d_k,device,dtype)\n",
            "        W_K = Linear(d_model, num_heads*self.d_k,device,dtype)\n",
            "        W_V = Linear(d_model, num_heads*self.d_v,device,dtype)\n",
            "        W_O = Linear(num_heads*self.d_v, d_model,device,dtype)\n",
            "\n",
            "        if (theta is not None) and (max_seq_len is not None):\n",
            "            self.rope = RotaryPositionalEmbedding(theta, self.d_k, max_seq_len)\n",
            "\n",
            "    def forward(\n",
            "        self, x: torch.Tensor,\n",
            "        token_position: torch.Tensor|None=None,\n",
            "    ) -> torch.Tensor:\n",
            "        Q = self.W_Q(x)\n",
            "        K = self.W_K(x)\n",
            "        V = self.W_V(x)\n",
            "\n",
            "        Q = rearrange(\n",
            "            Q,\n",
            "            \"batch seq (num_heads d_k) -> batch num_heads seq d_k\",\n",
            "            num_heads=self.num_heads\n",
            "        )\n",
            "        K = rearrange(\n",
            "            K,\n",
            "            \"batch seq (num_heads d_k) -> batch num_heads seq d_k\",\n",
            "            num_heads=self.num_heads\n",
            "        )\n",
            "        V = rearrange(\n",
            "            V,\n",
            "            \"batch seq (num_heads d_v) -> batch num_heads seq d_v\",\n",
            "            num_heads=self.num_heads\n",
            "        )\n",
            "\n",
            "        seq_len = Q.shape[-2]\n",
            "\n",
            "        # token_position = repeat(\n",
            "        #     torch.arange(seq_len),\n",
            "        #     \"seq -> batch num_heads seq\",\n",
            "        #     batch=batch_size,\n",
            "        #     num_heads=num_heads\n",
            "        # )\n",
            "        \n",
            "        if (self.rope is not None) and (token_position is not None):\n",
            "            Q = self.rope(Q, token_position)\n",
            "            K = self.rope(K, token_position)\n",
            "\n",
            "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=0).bool()\n",
            "        QKV = scaled_dot_product_attention(Q,K,V,mask)\n",
            "        QKV_reshape = rearrange(\n",
            "            QKV,\n",
            "            \"batch num_heads seq d_v -> batch seq (num_heads d_v)\"\n",
            "        )\n",
            "        result = self.W_O(QKV_reshape)\n",
            "        return result\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "id": "152a7714",
         "metadata": {},
         "outputs": [],
         "source": [
            "d_model = 16\n",
            "num_heads = 4\n",
            "\n",
            "theta = 2\n",
            "max_seq_len = 100"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "id": "4d791def",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "tensor([[[ 0.4357,  0.5501,  0.3195, -0.7769,  0.0510, -0.4412, -0.2595,\n",
                  "          -1.5785,  1.4489,  0.0391, -0.2899,  0.1485,  1.4783, -0.8320,\n",
                  "           0.4811,  0.7672],\n",
                  "         [-0.4532, -1.0519, -2.1271, -0.9563, -0.5471, -1.0961, -1.0668,\n",
                  "          -0.6359, -2.0603, -0.1888,  0.9379, -1.0534, -0.2707,  0.7150,\n",
                  "           0.2585,  0.3702],\n",
                  "         [ 1.5414,  0.1439, -0.3604,  1.2360, -0.0041, -0.4724, -0.8149,\n",
                  "          -0.3018, -1.3162, -0.5365,  1.7381, -1.5125, -2.0367,  0.0171,\n",
                  "           0.4785, -0.0124]],\n",
                  "\n",
                  "        [[ 0.8033,  0.2236, -0.1552, -0.1383, -1.8450,  0.8227, -2.4821,\n",
                  "           1.6230, -0.5547,  0.1371, -0.0919, -1.5927, -0.0959, -2.1357,\n",
                  "          -0.3561, -1.1158],\n",
                  "         [-2.3072, -0.1718,  1.5170, -0.3445,  0.8949,  0.0707,  1.0895,\n",
                  "           1.0088, -0.1453, -0.8405, -0.4352,  0.4360, -0.5356, -0.4802,\n",
                  "           0.0862,  0.3063],\n",
                  "         [ 2.6335,  0.8828, -0.6398, -0.3546, -0.4464,  1.1500,  0.5257,\n",
                  "           0.6860, -0.5160,  0.2141,  1.9333,  0.0619, -0.8618, -0.8927,\n",
                  "           0.7401, -1.5056]]])\n"
               ]
            }
         ],
         "source": [
            "from cs336_basics.transformer import Linear, RotaryPositionalEmbedding,scaled_dot_product_attention\n",
            "\n",
            "\n",
            "\n",
            "batch_size = 2\n",
            "seq_len = 3\n",
            "d_k = d_v = int(d_model/num_heads)\n",
            "x = torch.randn(batch_size, seq_len, d_model)\n",
            "print(x)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "id": "b78d3033",
         "metadata": {},
         "outputs": [],
         "source": [
            "W_Q = Linear(d_model, num_heads*d_k)\n",
            "W_K = Linear(d_model, num_heads*d_k)\n",
            "W_V = Linear(d_model, num_heads*d_v)\n",
            "W_O = Linear(num_heads*d_v, d_model)\n",
            "\n",
            "Q = W_Q(x)\n",
            "K = W_K(x)\n",
            "V = W_V(x)\n",
            "\n",
            "Q = rearrange(\n",
            "    Q,\n",
            "    \"batch seq (num_heads d_k) -> batch num_heads seq d_k\",\n",
            "    num_heads=num_heads\n",
            ")\n",
            "K = rearrange(\n",
            "    K,\n",
            "    \"batch seq (num_heads d_k) -> batch num_heads seq d_k\",\n",
            "    num_heads=num_heads\n",
            ")\n",
            "V = rearrange(\n",
            "    V,\n",
            "    \"batch seq (num_heads d_v) -> batch num_heads seq d_v\",\n",
            "    num_heads=num_heads\n",
            ")\n",
            "\n",
            "rope = RotaryPositionalEmbedding(theta, d_k, max_seq_len)\n",
            "token_position = repeat(\n",
            "    torch.arange(seq_len),\n",
            "    \"seq -> batch num_heads seq\",\n",
            "    batch=batch_size,\n",
            "    num_heads=num_heads\n",
            ")\n",
            "Q_rope = rope(Q, token_position)\n",
            "K_rope = rope(K, token_position)\n",
            "\n",
            "mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=0).bool()\n",
            "QKV = scaled_dot_product_attention(Q_rope,K_rope,V,mask)\n",
            "QKV_reshape = rearrange(\n",
            "    QKV,\n",
            "    \"batch num_heads seq d_v -> batch seq (num_heads d_v)\"\n",
            ")\n",
            "result = W_O(QKV_reshape)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "id": "e229b348",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "torch.Size([2, 4, 3, 4])"
                  ]
               },
               "execution_count": 9,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "QKV.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "id": "6d5a5cd8",
         "metadata": {},
         "outputs": [
            {
               "ename": "AttributeError",
               "evalue": "'Linear' object has no attribute 'shape'",
               "output_type": "error",
               "traceback": [
                  "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                  "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
                  "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mW_O\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\n",
                  "\u001b[36mFile \u001b[39m\u001b[32m~/Github/stanford-cs336/stanford-cs336-assignment1-basics/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1928\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1926\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1927\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1928\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1929\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1930\u001b[39m )\n",
                  "\u001b[31mAttributeError\u001b[39m: 'Linear' object has no attribute 'shape'"
               ]
            }
         ],
         "source": [
            "W_O.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "id": "2ed9b7e3",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[16, 16]"
                  ]
               },
               "execution_count": 12,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "[num_heads*d_v, d_model]"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "a3779fa8",
         "metadata": {},
         "source": [
            "**有两个大问题。一是对于QK的softmax方向，二是对于上下三角。**"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "6240f01d",
         "metadata": {},
         "source": [
            "### 3.6 The Full Transformer LM"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "9a7cacf2",
         "metadata": {},
         "source": [
            "##### transformer_block"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "d419eebf",
         "metadata": {},
         "outputs": [],
         "source": [
            "from cs336_basics.transformer import (\n",
            "    MultiheadSelfAttention,\n",
            "    RMSNorm,\n",
            "    SwiGLU\n",
            ")\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "49b354e7",
         "metadata": {},
         "outputs": [],
         "source": [
            "class TransformerBlock(nn.Module):\n",
            "    def __init__(\n",
            "        self, \n",
            "        d_model: int, \n",
            "        num_heads: int, \n",
            "        d_ff: int,\n",
            "        eps: float = 1e-5, \n",
            "        theta: float|None=None,\n",
            "        max_seq_len:int|None=None,\n",
            "        device: torch.device | None = None, \n",
            "        dtype: torch.dtype | None = None\n",
            "    ):\n",
            "        super().__init__()\n",
            "        self.d_model = d_model\n",
            "        self.num_heads = num_heads\n",
            "        self.d_ff = d_ff\n",
            "        self.eps = eps\n",
            "        self.theta = theta\n",
            "        self.max_seq_len = max_seq_len\n",
            "        self.device = device\n",
            "        self.dtype = dtype\n",
            "\n",
            "        self.multihead_attention = MultiheadSelfAttention(\n",
            "            d_model,num_heads,theta,max_seq_len,device,dtype\n",
            "        )\n",
            "        self.rms_norm1 = RMSNorm(d_model,eps,device,dtype)\n",
            "        self.rms_norm2 = RMSNorm(d_model,eps,device,dtype)\n",
            "        self.swi_glu = SwiGLU(d_model,d_ff,device,dtype)\n",
            "\n",
            "    def forward(\n",
            "        self, x: torch.Tensor,\n",
            "        token_position: torch.Tensor|None=None,\n",
            "    ) -> torch.Tensor:\n",
            "        x_norm = self.rms_norm1(x)\n",
            "        x_attention = self.multihead_attention(x_norm, token_position)\n",
            "        x2 = x + x_attention\n",
            "        x2_norm = self.rms_norm2(x2)\n",
            "        x2_glu = self.swi_glu(x2_norm)\n",
            "        x3 = x2 + x2_glu\n",
            "        return x3\n",
            "\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "120610d9",
         "metadata": {},
         "source": [
            "##### transformer_lm"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "id": "6547a8f9",
         "metadata": {},
         "outputs": [],
         "source": [
            "from cs336_basics.transformer import (\n",
            "    Embedding,\n",
            "    TransformerBlock,\n",
            "    RMSNorm,\n",
            "    Linear,\n",
            "    softmax\n",
            ")\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "842a7d63",
         "metadata": {},
         "outputs": [],
         "source": [
            "class TransformerLM(nn.Module):\n",
            "    def __init__(\n",
            "        self, \n",
            "        vocab_size: int,\n",
            "        context_length: int,\n",
            "        num_layers: int,\n",
            "        d_model: int, \n",
            "        num_heads: int, \n",
            "        d_ff: int,\n",
            "        eps: float = 1e-5, \n",
            "        theta: float|None=None,\n",
            "        device: torch.device | None = None, \n",
            "        dtype: torch.dtype | None = None\n",
            "    ):\n",
            "        super().__init__()\n",
            "        self.vocab_size = vocab_size\n",
            "        self.context_length = context_length\n",
            "        self.num_layers = num_layers\n",
            "        self.d_model = d_model\n",
            "        self.num_heads = num_heads\n",
            "        self.d_ff = d_ff\n",
            "        self.eps = eps\n",
            "        self.theta = theta\n",
            "        self.device = device\n",
            "        self.dtype = dtype\n",
            "\n",
            "        self.embedding = Embedding(vocab_size,d_ff,device,dtype)\n",
            "        self.transformer_blocks = nn.ModuleList([\n",
            "            TransformerBlock(d_model, num_heads, d_ff, rope_theta, context_length, device, dtype)\n",
            "            for _ in range(num_layers)\n",
            "        ])\n",
            "        self.rms_norm = RMSNorm(d_model,eps,device,dtype)\n",
            "        self.linear = Linear(d_model,vocab_size,device,dtype)\n",
            "\n",
            "    def forward(\n",
            "        self, x: torch.Tensor\n",
            "    ) -> torch.Tensor:\n",
            "        x_embedded = self.embedding(x)\n",
            "        for block in self.transformer_blocks:\n",
            "            x_embedded = block(x_embedded)\n",
            "        x_norm = self.rms_norm(x_embedded)\n",
            "        x_linear = self.linear(x_norm)\n",
            "        result = softmax(x_linear, dim=-1)\n",
            "        return result\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "3bb92021",
         "metadata": {},
         "source": [
            "Suppose:\n",
            "1. vocab_size = v\n",
            "2. context_length = s\n",
            "3. number_layer = N\n",
            "4. d_model = d\n",
            "5. n_head = h\n",
            "6. d_ff = f\n",
            "\n",
            "| Layer1      | Layer2    | Layer3 | Input_dim | weights_dim | Flop | N_para |\n",
            "| :-----      | :-----    | :----- | :-------- | :---------- | :--- | :---   |\n",
            "| Input       |           |        | 0         | s           | 0    | 0      |\n",
            "| Embedding   |           |        | s         | d*v         | 0    | dv     |\n",
            "| Transformer | Attention | get QKV| d*s       | d*d         | 6d^2s| 3d^2   |\n",
            "|             |           | ROPE   | d*s       |             | 2ds  | 0      |\n",
            "|             |           | QK     | s\\*d/h\\*h | s\\*d/h\\*h   | 2ds^2| 0      |\n",
            "|             |           | softmax|           |             | O(hs^2)| 0    |\n",
            "|             |           | KV     | s\\*d/h\\*h | s\\*d/h\\*h   | 2ds^2| 0      |\n",
            "|             |           | Output | d*s       | d*d         | 2d^2s| d^2    |\n",
            "|             | SwiGLU    | W1     | d*s       | d*f         | 2dsf | df     |\n",
            "|             |           | W2     | f*s       | d*f         | 2dsf | df     |\n",
            "|             |           | W3     | d*s       | d*f         | 2dsf | df     |\n",
            "|             | RMS       |        |           |             | O(ds)| 2d     |\n",
            "| RMS         |           |        |           |             |      | d      |\n",
            "| Linear      |           |        | d*s       | d*v         | 2dsv | dv     |\n",
            "\n",
            "N*(8d^2s+4ds^2+6dsf)+2dsv"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "id": "c0d3748f",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "\n",
                  "Detailed Layer-by-Layer Analysis (Single Block/Layer Stats):\n",
                  "         Layer1     Layer2   Layer3 Input_dim Weights_dim          Flop  \\\n",
                  "0         Input                             0           s             0   \n",
                  "1     Embedding                             s         d*v             0   \n",
                  "2   Transformer  Attention  get QKV       d*s       3*d*d   15728640000   \n",
                  "3                              ROPE       d*s           0       3276800   \n",
                  "4                                QK       s*d         s*d    3355443200   \n",
                  "5                           softmax     h*s*s           0     131072000   \n",
                  "6                                KV       s*s         s*d    3355443200   \n",
                  "7                            Output       d*s         d*d    5242880000   \n",
                  "8                   SwiGLU       W1       d*s         d*f   20971520000   \n",
                  "9                                W3       d*s         d*f   20971520000   \n",
                  "10                               W2       f*s         d*f   20971520000   \n",
                  "11                     RMS       x2       d*s         2*d      16384000   \n",
                  "12          RMS      Final                d*s           d       8192000   \n",
                  "13       Linear     Output                d*s         d*v  164682137600   \n",
                  "\n",
                  "      N_para  \n",
                  "0          0  \n",
                  "1   80411200  \n",
                  "2    7680000  \n",
                  "3          0  \n",
                  "4          0  \n",
                  "5          0  \n",
                  "6          0  \n",
                  "7    2560000  \n",
                  "8   10240000  \n",
                  "9   10240000  \n",
                  "10  10240000  \n",
                  "11      3200  \n",
                  "12      1600  \n",
                  "13  80411200  \n",
                  "\n",
                  "========================================\n",
                  "Summary for N = 48 layers:\n",
                  "- Total Parameters: 2.127 Billion\n",
                  "- Total FLOPs:      4.521 TFLOPs\n",
                  "- Memory (FP32):    7.92 GB\n",
                  "========================================\n"
               ]
            }
         ],
         "source": [
            "def analyze_transformer_to_df(v, s, N, d, f, h):\n",
            "    # 定义每一行的数据逻辑 [Layer1, Layer2, Layer3, Input, Weights, Flop, N_para]\n",
            "    data = [\n",
            "        [\"Input\", \"\", \"\", \"0\", \"s\", 0, 0],\n",
            "        [\"Embedding\", \"\", \"\", \"s\", \"d*v\", 0, d * v],\n",
            "        \n",
            "        # Transformer Block 内部 (这里计算单层)\n",
            "        [\"Transformer\", \"Attention\", \"get QKV\", \"d*s\", \"3*d*d\", 6 * (d**2) * s, 3 * (d**2)],\n",
            "        [\"\", \"\", \"ROPE\", \"d*s\", \"0\", 2 * d * s, 0],\n",
            "        [\"\", \"\", \"QK\", \"s*d\", \"s*d\", 2 * d * (s**2), 0],\n",
            "        [\"\", \"\", \"softmax\", \"h*s*s\", \"0\", 5 * h * (s**2), 0],\n",
            "        [\"\", \"\", \"KV\", \"s*s\", \"s*d\", 2 * d * (s**2), 0],\n",
            "        [\"\", \"\", \"Output\", \"d*s\", \"d*d\", 2 * (d**2) * s, d**2],\n",
            "        \n",
            "        [\"\", \"SwiGLU\", \"W1\", \"d*s\", \"d*f\", 2 * d * s * f, d * f],\n",
            "        [\"\", \"\", \"W3\", \"d*s\", \"d*f\", 2 * d * s * f, d * f],\n",
            "        [\"\", \"\", \"W2\", \"f*s\", \"d*f\", 2 * d * s * f, d * f],\n",
            "        \n",
            "        [\"\", \"RMS\", \"x2\", \"d*s\", \"2*d\", 10 * d * s, 2 * d],\n",
            "        \n",
            "        # Final layers\n",
            "        [\"RMS\", \"Final\", \"\", \"d*s\", \"d\", 5 * d * s, d],\n",
            "        [\"Linear\", \"Output\", \"\", \"d*s\", \"d*v\", 2 * d * s * v, d * v]\n",
            "    ]\n",
            "\n",
            "    columns = [\"Layer1\", \"Layer2\", \"Layer3\", \"Input_dim\", \"Weights_dim\", \"Flop\", \"N_para\"]\n",
            "    df = pd.DataFrame(data, columns=columns)\n",
            "\n",
            "    # 计算 Block 内部的合计数（用于乘以 N 层）\n",
            "    block_mask = df[\"Layer1\"].isin([\"Transformer\", \"\"]) & ~df[\"Layer2\"].isin([\"Output\", \"Final\"])\n",
            "    block_flops = df.loc[block_mask, \"Flop\"].sum()\n",
            "    block_params = df.loc[block_mask, \"N_para\"].sum()\n",
            "\n",
            "    # 计算总计 (注意：Embedding 和 Linear Output 不随 N 变化)\n",
            "    total_params = (block_params * N) + (d * v * 2) + d # 词表双向+最后Norm\n",
            "    total_flops = (block_flops * N) + (2 * d * s * v)\n",
            "\n",
            "    # 打印 DataFrame (美化显示)\n",
            "    pd.options.display.float_format = '{:,.0f}'.format\n",
            "    print(\"\\nDetailed Layer-by-Layer Analysis (Single Block/Layer Stats):\")\n",
            "    print(df)\n",
            "\n",
            "    print(f\"\\n{'='*40}\")\n",
            "    print(f\"Summary for N = {N} layers:\")\n",
            "    print(f\"- Total Parameters: {total_params / 1e9:.3f} Billion\")\n",
            "    print(f\"- Total FLOPs:      {total_flops / 1e12:.3f} TFLOPs\")\n",
            "    print(f\"- Memory (FP32):    {total_params * 4 / (1024**3):.2f} GB\")\n",
            "    print(f\"{'='*40}\")\n",
            "\n",
            "    return df\n",
            "\n",
            "# 设置参数\n",
            "params = {\n",
            "    \"v\": 50257,\n",
            "    \"s\": 1024,\n",
            "    \"N\": 48,\n",
            "    \"d\": 1600,\n",
            "    \"f\": 6400,\n",
            "    \"h\": 25\n",
            "}\n",
            "\n",
            "df_result = analyze_transformer_to_df(**params)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 22,
         "id": "aeb6b22a",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "\n",
                  "Detailed Layer-by-Layer Analysis (Single Block/Layer Stats):\n",
                  "         Layer1     Layer2   Layer3 Input_dim Weights_dim         Flop  \\\n",
                  "0         Input                             0           s            0   \n",
                  "1     Embedding                             s         d*v            0   \n",
                  "2   Transformer  Attention  get QKV       d*s       3*d*d   3623878656   \n",
                  "3                              ROPE       d*s           0      1572864   \n",
                  "4                                QK       s*d         s*d   1610612736   \n",
                  "5                           softmax     h*s*s           0     62914560   \n",
                  "6                                KV       s*s         s*d   1610612736   \n",
                  "7                            Output       d*s         d*d   1207959552   \n",
                  "8                   SwiGLU       W1       d*s         d*f  10066329600   \n",
                  "9                                W3       d*s         d*f  10066329600   \n",
                  "10                               W2       f*s         d*f  10066329600   \n",
                  "11                     RMS       x2       d*s         2*d      7864320   \n",
                  "12          RMS      Final                d*s           d      3932160   \n",
                  "13       Linear     Output                d*s         d*v  79047426048   \n",
                  "\n",
                  "      N_para  \n",
                  "0          0  \n",
                  "1   38597376  \n",
                  "2    1769472  \n",
                  "3          0  \n",
                  "4          0  \n",
                  "5          0  \n",
                  "6          0  \n",
                  "7     589824  \n",
                  "8    4915200  \n",
                  "9    4915200  \n",
                  "10   4915200  \n",
                  "11      1536  \n",
                  "12       768  \n",
                  "13  38597376  \n",
                  "\n",
                  "========================================\n",
                  "Summary for N = 12 layers:\n",
                  "- Total Parameters: 0.282 Billion\n",
                  "- Total FLOPs:      0.539 TFLOPs\n",
                  "- Memory (FP32):    1.05 GB\n",
                  "========================================\n"
               ]
            }
         ],
         "source": [
            "params = {\n",
            "    \"v\": 50257,\n",
            "    \"s\": 1024,\n",
            "    \"N\": 12,\n",
            "    \"d\": 768,\n",
            "    \"f\": 6400,\n",
            "    \"h\": 12\n",
            "}\n",
            "\n",
            "df_result = analyze_transformer_to_df(**params)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 23,
         "id": "7603e6dc",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "\n",
                  "Detailed Layer-by-Layer Analysis (Single Block/Layer Stats):\n",
                  "         Layer1     Layer2   Layer3 Input_dim Weights_dim          Flop  \\\n",
                  "0         Input                             0           s             0   \n",
                  "1     Embedding                             s         d*v             0   \n",
                  "2   Transformer  Attention  get QKV       d*s       3*d*d    6442450944   \n",
                  "3                              ROPE       d*s           0       2097152   \n",
                  "4                                QK       s*d         s*d    2147483648   \n",
                  "5                           softmax     h*s*s           0      83886080   \n",
                  "6                                KV       s*s         s*d    2147483648   \n",
                  "7                            Output       d*s         d*d    2147483648   \n",
                  "8                   SwiGLU       W1       d*s         d*f   13421772800   \n",
                  "9                                W3       d*s         d*f   13421772800   \n",
                  "10                               W2       f*s         d*f   13421772800   \n",
                  "11                     RMS       x2       d*s         2*d      10485760   \n",
                  "12          RMS      Final                d*s           d       5242880   \n",
                  "13       Linear     Output                d*s         d*v  105396568064   \n",
                  "\n",
                  "      N_para  \n",
                  "0          0  \n",
                  "1   51463168  \n",
                  "2    3145728  \n",
                  "3          0  \n",
                  "4          0  \n",
                  "5          0  \n",
                  "6          0  \n",
                  "7    1048576  \n",
                  "8    6553600  \n",
                  "9    6553600  \n",
                  "10   6553600  \n",
                  "11      2048  \n",
                  "12      1024  \n",
                  "13  51463168  \n",
                  "\n",
                  "========================================\n",
                  "Summary for N = 24 layers:\n",
                  "- Total Parameters: 0.675 Billion\n",
                  "- Total FLOPs:      1.383 TFLOPs\n",
                  "- Memory (FP32):    2.52 GB\n",
                  "========================================\n"
               ]
            }
         ],
         "source": [
            "params = {\n",
            "    \"v\": 50257,\n",
            "    \"s\": 1024,\n",
            "    \"N\": 24,\n",
            "    \"d\": 1024,\n",
            "    \"f\": 6400,\n",
            "    \"h\": 16\n",
            "}\n",
            "\n",
            "df_result = analyze_transformer_to_df(**params)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "id": "fd048f06",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "\n",
                  "Detailed Layer-by-Layer Analysis (Single Block/Layer Stats):\n",
                  "         Layer1     Layer2   Layer3 Input_dim Weights_dim          Flop  \\\n",
                  "0         Input                             0           s             0   \n",
                  "1     Embedding                             s         d*v             0   \n",
                  "2   Transformer  Attention  get QKV       d*s       3*d*d   10066329600   \n",
                  "3                              ROPE       d*s           0       2621440   \n",
                  "4                                QK       s*d         s*d    2684354560   \n",
                  "5                           softmax     h*s*s           0     104857600   \n",
                  "6                                KV       s*s         s*d    2684354560   \n",
                  "7                            Output       d*s         d*d    3355443200   \n",
                  "8                   SwiGLU       W1       d*s         d*f   16777216000   \n",
                  "9                                W3       d*s         d*f   16777216000   \n",
                  "10                               W2       f*s         d*f   16777216000   \n",
                  "11                     RMS       x2       d*s         2*d      13107200   \n",
                  "12          RMS      Final                d*s           d       6553600   \n",
                  "13       Linear     Output                d*s         d*v  131745710080   \n",
                  "\n",
                  "      N_para  \n",
                  "0          0  \n",
                  "1   64328960  \n",
                  "2    4915200  \n",
                  "3          0  \n",
                  "4          0  \n",
                  "5          0  \n",
                  "6          0  \n",
                  "7    1638400  \n",
                  "8    8192000  \n",
                  "9    8192000  \n",
                  "10   8192000  \n",
                  "11      2560  \n",
                  "12      1280  \n",
                  "13  64328960  \n",
                  "\n",
                  "========================================\n",
                  "Summary for N = 36 layers:\n",
                  "- Total Parameters: 1.249 Billion\n",
                  "- Total FLOPs:      2.624 TFLOPs\n",
                  "- Memory (FP32):    4.65 GB\n",
                  "========================================\n"
               ]
            }
         ],
         "source": [
            "params = {\n",
            "    \"v\": 50257,\n",
            "    \"s\": 1024,\n",
            "    \"N\": 36,\n",
            "    \"d\": 1280,\n",
            "    \"f\": 6400,\n",
            "    \"h\": 20\n",
            "}\n",
            "\n",
            "df_result = analyze_transformer_to_df(**params)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 25,
         "id": "a36f745e",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "\n",
                  "Detailed Layer-by-Layer Analysis (Single Block/Layer Stats):\n",
                  "         Layer1     Layer2   Layer3 Input_dim Weights_dim           Flop  \\\n",
                  "0         Input                             0           s              0   \n",
                  "1     Embedding                             s         d*v              0   \n",
                  "2   Transformer  Attention  get QKV       d*s       3*d*d   251658240000   \n",
                  "3                              ROPE       d*s           0       52428800   \n",
                  "4                                QK       s*d         s*d   858993459200   \n",
                  "5                           softmax     h*s*s           0    33554432000   \n",
                  "6                                KV       s*s         s*d   858993459200   \n",
                  "7                            Output       d*s         d*d    83886080000   \n",
                  "8                   SwiGLU       W1       d*s         d*f   335544320000   \n",
                  "9                                W3       d*s         d*f   335544320000   \n",
                  "10                               W2       f*s         d*f   335544320000   \n",
                  "11                     RMS       x2       d*s         2*d      262144000   \n",
                  "12          RMS      Final                d*s           d      131072000   \n",
                  "13       Linear     Output                d*s         d*v  2634914201600   \n",
                  "\n",
                  "      N_para  \n",
                  "0          0  \n",
                  "1   80411200  \n",
                  "2    7680000  \n",
                  "3          0  \n",
                  "4          0  \n",
                  "5          0  \n",
                  "6          0  \n",
                  "7    2560000  \n",
                  "8   10240000  \n",
                  "9   10240000  \n",
                  "10  10240000  \n",
                  "11      3200  \n",
                  "12      1600  \n",
                  "13  80411200  \n",
                  "\n",
                  "========================================\n",
                  "Summary for N = 48 layers:\n",
                  "- Total Parameters: 2.127 Billion\n",
                  "- Total FLOPs:      151.149 TFLOPs\n",
                  "- Memory (FP32):    7.92 GB\n",
                  "========================================\n"
               ]
            }
         ],
         "source": [
            "params = {\n",
            "    \"v\": 50257,\n",
            "    \"s\": 16384,\n",
            "    \"N\": 48,\n",
            "    \"d\": 1600,\n",
            "    \"f\": 6400,\n",
            "    \"h\": 25\n",
            "}\n",
            "\n",
            "df_result = analyze_transformer_to_df(**params)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "944083f2",
         "metadata": {},
         "source": [
            "## 4 Training a Transformer LM"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "18ec825a",
         "metadata": {},
         "source": [
            "### 4.1 Cross-entropy loss"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "a19dcf5c",
         "metadata": {},
         "outputs": [],
         "source": [
            "def cross_entropy(\n",
            "    prediction: torch.Tensor,\n",
            "    target: torch.Tensor\n",
            "):\n",
            "    max_values, _ = torch.max(prediction, dim = -1, keepdim=True)\n",
            "    prediction_scaled = prediction - max_values\n",
            "    prediction_scaled_exp = torch.exp(prediction_scaled)\n",
            "    prediction_scaled_exp_sum = torch.sum(prediction_scaled_exp, dim = -1)\n",
            "    prediction_scaled_exp_sum_log = torch.log(prediction_scaled_exp_sum)\n",
            "    target_expend = rearrange(\n",
            "        target,\n",
            "        \"... -> ... 1\"\n",
            "    )\n",
            "    target_logits = torch.gather(prediction_scaled, -1, target_expend)\n",
            "    result = - target_logits + prediction_scaled_exp_sum_log\n",
            "    return result"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 29,
         "id": "15fd327f",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
                     "        [0.1818, 0.2273, 0.2727, 0.3182]])"
                  ]
               },
               "execution_count": 29,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "batch = 2\n",
            "vocab_size = 4\n",
            "\n",
            "prediction = torch.arange(batch*vocab_size).reshape(batch,vocab_size)\n",
            "prediction_sum = torch.sum(prediction, dim = -1, keepdim=True)\n",
            "prediction = prediction/prediction_sum\n",
            "target = torch.randint(0,vocab_size,(batch,))\n",
            "prediction\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 30,
         "id": "22b2c65d",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[-0.5000, -0.3333, -0.1667,  0.0000],\n",
                     "        [-0.1364, -0.0909, -0.0455,  0.0000]])"
                  ]
               },
               "execution_count": 30,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "max_values, _ = torch.max(prediction, dim = -1, keepdim=True)\n",
            "prediction_scaled = prediction - max_values\n",
            "prediction_scaled"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 31,
         "id": "5e53eba8",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([1.1536, 1.3194])"
                  ]
               },
               "execution_count": 31,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "prediction_scaled_exp = torch.exp(prediction_scaled)\n",
            "prediction_scaled_exp_sum = torch.sum(prediction_scaled_exp, dim = -1)\n",
            "prediction_scaled_exp_sum_log = torch.log(prediction_scaled_exp_sum)\n",
            "prediction_scaled_exp_sum_log"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 38,
         "id": "ded88951",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([-0.5000,  0.0000])"
                  ]
               },
               "execution_count": 38,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "target_expend = rearrange(\n",
            "    target,\n",
            "    \"... -> ... 1\"\n",
            ")\n",
            "\n",
            "target_logits = torch.gather(prediction_scaled, -1, target_expend)\n",
            "target_logits = rearrange(\n",
            "    target_logits,\n",
            "    \"... 1 -> ...\"\n",
            ")\n",
            "target_logits"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 39,
         "id": "0a175e95",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([1.6536, 1.3194])"
                  ]
               },
               "execution_count": 39,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "result = - target_logits + prediction_scaled_exp_sum_log\n",
            "result"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "0c97945e",
         "metadata": {},
         "source": [
            "### 4.2 The SGD Optimizer"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "29fc13d5",
         "metadata": {},
         "source": [
            "#### 4.2.1 Implementing SGD in PyTorch"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "0c9f4773",
         "metadata": {},
         "outputs": [],
         "source": [
            "class SGD(torch.optim.Optimizer):\n",
            "    def __init__(self, params, lr=1e-3):\n",
            "        if lr < 0:\n",
            "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
            "        defaults = {\"lr\": lr}\n",
            "        super().__init__(params, defaults)\n",
            "\n",
            "    def step(self, closure: Optional[Callable] = None):\n",
            "        loss = None if closure is None else closure()\n",
            "        for group in self.param_groups:\n",
            "            lr = group[\"lr\"] # Get the learning rate.\n",
            "            for p in group[\"params\"]:\n",
            "                if p.grad is None:\n",
            "                    continue\n",
            "                state = self.state[p] # Get state associated with p.\n",
            "                t = state.get(\"t\", 0) # Get iteration number from the state, or initial value.\n",
            "                grad = p.grad.data # Get the gradient of loss with respect to p.\n",
            "                p.data -= lr / math.sqrt(t + 1) * grad # Update weight tensor in-place.\n",
            "                state[\"t\"] = t + 1\n",
            "        return loss"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 42,
         "id": "e808926f",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "20.437528610229492\n",
                  "19.628202438354492\n",
                  "19.07695770263672\n",
                  "18.638938903808594\n",
                  "18.268024444580078\n",
                  "17.94269561767578\n",
                  "17.650890350341797\n",
                  "17.385042190551758\n",
                  "17.14004898071289\n",
                  "16.912277221679688\n",
                  "16.69902992248535\n",
                  "16.49823760986328\n",
                  "16.30828285217285\n",
                  "16.12786293029785\n",
                  "15.955907821655273\n",
                  "15.791542053222656\n",
                  "15.634020805358887\n",
                  "15.482717514038086\n",
                  "15.337088584899902\n",
                  "15.19666862487793\n",
                  "15.061049461364746\n",
                  "14.929871559143066\n",
                  "14.80282211303711\n",
                  "14.679614067077637\n",
                  "14.560001373291016\n",
                  "14.443753242492676\n",
                  "14.330670356750488\n",
                  "14.220563888549805\n",
                  "14.113271713256836\n",
                  "14.008635520935059\n",
                  "13.906517028808594\n",
                  "13.806788444519043\n",
                  "13.709332466125488\n",
                  "13.614039421081543\n",
                  "13.520807266235352\n",
                  "13.429544448852539\n",
                  "13.340163230895996\n",
                  "13.252582550048828\n",
                  "13.166728973388672\n",
                  "13.082529067993164\n",
                  "12.999919891357422\n",
                  "12.918835639953613\n",
                  "12.839221954345703\n",
                  "12.761022567749023\n",
                  "12.684186935424805\n",
                  "12.608667373657227\n",
                  "12.534415245056152\n",
                  "12.461386680603027\n",
                  "12.389545440673828\n",
                  "12.31885051727295\n",
                  "12.249261856079102\n",
                  "12.180747985839844\n",
                  "12.113275527954102\n",
                  "12.0468111038208\n",
                  "11.98132610321045\n",
                  "11.916790962219238\n",
                  "11.853178977966309\n",
                  "11.790461540222168\n",
                  "11.728615760803223\n",
                  "11.667618751525879\n",
                  "11.607443809509277\n",
                  "11.548073768615723\n",
                  "11.489483833312988\n",
                  "11.43165397644043\n",
                  "11.374567985534668\n",
                  "11.318203926086426\n",
                  "11.26254653930664\n",
                  "11.207575798034668\n",
                  "11.153276443481445\n",
                  "11.099634170532227\n",
                  "11.046630859375\n",
                  "10.994253158569336\n",
                  "10.942487716674805\n",
                  "10.891318321228027\n",
                  "10.840733528137207\n",
                  "10.790719985961914\n",
                  "10.741266250610352\n",
                  "10.692359924316406\n",
                  "10.643986701965332\n",
                  "10.596138954162598\n",
                  "10.548803329467773\n",
                  "10.501972198486328\n",
                  "10.455633163452148\n",
                  "10.409777641296387\n",
                  "10.364396095275879\n",
                  "10.319477081298828\n",
                  "10.275014877319336\n",
                  "10.230997085571289\n",
                  "10.187419891357422\n",
                  "10.144269943237305\n",
                  "10.101543426513672\n",
                  "10.059229850769043\n",
                  "10.017324447631836\n",
                  "9.975817680358887\n",
                  "9.934703826904297\n",
                  "9.893973350524902\n",
                  "9.853623390197754\n",
                  "9.813643455505371\n",
                  "9.774030685424805\n",
                  "9.734777450561523\n"
               ]
            }
         ],
         "source": [
            "weights = torch.nn.Parameter(5 * torch.randn((10, 10)))\n",
            "opt = SGD([weights], lr=1)\n",
            "for t in range(100):\n",
            "    opt.zero_grad() # Reset the gradients for all learnable parameters.\n",
            "    loss = (weights**2).mean() # Compute a scalar loss value.\n",
            "    print(loss.cpu().item())\n",
            "    loss.backward() # Run backward pass, which computes gradients.\n",
            "    opt.step() # Run optimizer step."
         ]
      },
      {
         "cell_type": "markdown",
         "id": "b6671aea",
         "metadata": {},
         "source": [
            "### 4.3 AdamW"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 47,
         "id": "428fa4b0",
         "metadata": {},
         "outputs": [],
         "source": [
            "class AdamW(torch.optim.Optimizer):\n",
            "    def __init__(\n",
            "        self, params,\n",
            "        lr=1e-3,\n",
            "        eps=1e-8,\n",
            "        betas=(0.9, 0.999),\n",
            "        weight_decay=0\n",
            "    ):\n",
            "        if not 0.0 <= lr:\n",
            "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
            "        if not 0.0 <= eps:\n",
            "            raise ValueError(f\"Invalid epsilon value: {eps}\")\n",
            "        if not 0.0 <= betas[0] < 1.0:\n",
            "            raise ValueError(f\"Invalid beta parameter at index 0: {betas[0]}\")\n",
            "        if not 0.0 <= betas[1] < 1.0:\n",
            "            raise ValueError(f\"Invalid beta parameter at index 1: {betas[1]}\")\n",
            "        defaults = {\n",
            "            'lr': lr,\n",
            "            'betas': betas,\n",
            "            'eps': eps,\n",
            "            'weight_decay': weight_decay,\n",
            "        }\n",
            "        super().__init__(params, defaults)\n",
            "    \n",
            "    def step(self, closure: Optional[Callable] = None):\n",
            "        loss = None if closure is None else closure()\n",
            "        for group in self.param_groups:\n",
            "            lr = group[\"lr\"]\n",
            "            beta1 = group[\"betas\"][0]\n",
            "            beta2 = group[\"betas\"][1]\n",
            "            eps = group[\"eps\"] \n",
            "            weight_decay = group[\"weight_decay\"] \n",
            "            for p in group[\"params\"]:\n",
            "                if p.grad is None:\n",
            "                    continue\n",
            "                state = self.state[p]\n",
            "                g = p.grad.data\n",
            "\n",
            "\n",
            "                m = state.get('m',torch.zeros_like(p.data))\n",
            "                m = beta1*m+(1-beta1)*g\n",
            "                state['m'] = m\n",
            "\n",
            "                v = state.get('v',torch.zeros_like(p.data))\n",
            "                v = beta2*v+(1-beta2)*g**2\n",
            "                state['v'] = v\n",
            "\n",
            "                t = state.get(\"t\", 1)\n",
            "                state['t'] = t+1\n",
            "\n",
            "                lrt = lr*math.sqrt(1-beta2**t)/(1-beta1**t)\n",
            "\n",
            "                p.data -= lrt*m/(torch.sqrt(v)+eps)\n",
            "                if weight_decay != 0:\n",
            "                    p.data = p.data-lr*weight_decay*p.data\n",
            "        return loss"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "17c0b6bb",
         "metadata": {},
         "source": [
            "### 4.4 Learning rate scheduling"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "34c8f721",
         "metadata": {},
         "outputs": [],
         "source": [
            "def learning_rate_schedule(\n",
            "    t: int,\n",
            "    alpha_max: float,\n",
            "    alpha_min: float,\n",
            "    T_w: int,\n",
            "    T_c: int\n",
            "):\n",
            "    if t<T_w:\n",
            "        alpha_t = t*alpha_max/T_w\n",
            "    elif t<= T_c:\n",
            "        alpha_t = alpha_min + (alpha_max-alpha_min)*(1+math.cos((t-T_w)*math.pi/(T_c-T_w)))/2 \n",
            "    else:\n",
            "        alpha_t = alpha_min\n",
            "    return alpha_t "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "22fa595b",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "5e0f1e8d",
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.12.12"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}
