{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "153fa639",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da7993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f7a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f2e7f3",
   "metadata": {},
   "source": [
    "## 1 Assignment Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e287b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a80feac",
   "metadata": {},
   "source": [
    "## 2 Byte-Pair Encoding (BPE) Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcdbb3e",
   "metadata": {},
   "source": [
    "### 2.1 The Unicode Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9bf5df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29275, '牛']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ord('牛'), chr(29275)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a209ddd0",
   "metadata": {},
   "source": [
    "#### Problem (unicode1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1d9697",
   "metadata": {},
   "source": [
    "##### a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b90bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f463d9",
   "metadata": {},
   "source": [
    "##### b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f9fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\n"
     ]
    }
   ],
   "source": [
    "print(chr(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b6078b",
   "metadata": {},
   "source": [
    "##### c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96daa256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test\\x00string'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"this is a test\" + chr(0) + \"string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86647719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a test\u0000string\n"
     ]
    }
   ],
   "source": [
    "print(\"this is a test\" + chr(0) + \"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885fe342",
   "metadata": {},
   "source": [
    "### 2.2 Unicode Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12077a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello! \\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf!'\n"
     ]
    }
   ],
   "source": [
    "test_string = \"hello! こんにちは!\"\n",
    "utf8_encoded = test_string.encode(\"utf-8\")\n",
    "print(utf8_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc24edd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "print(type(utf8_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c38939e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[104,\n",
       " 101,\n",
       " 108,\n",
       " 108,\n",
       " 111,\n",
       " 33,\n",
       " 32,\n",
       " 227,\n",
       " 129,\n",
       " 147,\n",
       " 227,\n",
       " 130,\n",
       " 147,\n",
       " 227,\n",
       " 129,\n",
       " 171,\n",
       " 227,\n",
       " 129,\n",
       " 161,\n",
       " 227,\n",
       " 129,\n",
       " 175,\n",
       " 33]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(utf8_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3322f2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 23]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(test_string),len(utf8_encoded)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6bb20ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello! こんにちは!\n"
     ]
    }
   ],
   "source": [
    "print(utf8_encoded.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b18de75",
   "metadata": {},
   "source": [
    "#### Problem (unicode2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed709893",
   "metadata": {},
   "source": [
    "##### a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf37160",
   "metadata": {},
   "source": [
    "##### b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8cfb916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_utf8_bytes_to_str_wrong(bytestring: bytes):\n",
    "    return \"\".join([bytes([b]).decode(\"utf-8\") for b in bytestring])\n",
    "decode_utf8_bytes_to_str_wrong(\"hello\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35a3b6be",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe4 in position 0: unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdecode_utf8_bytes_to_str_wrong\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhello, 你好\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mdecode_utf8_bytes_to_str_wrong\u001b[39m\u001b[34m(bytestring)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_utf8_bytes_to_str_wrong\u001b[39m(bytestring: \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bytestring])\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xe4 in position 0: unexpected end of data"
     ]
    }
   ],
   "source": [
    "decode_utf8_bytes_to_str_wrong(\"hello, 你好\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b68518c",
   "metadata": {},
   "source": [
    "##### c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b92654d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'h',\n",
       " b'e',\n",
       " b'l',\n",
       " b'l',\n",
       " b'o',\n",
       " b',',\n",
       " b' ',\n",
       " b'\\xe4',\n",
       " b'\\xbd',\n",
       " b'\\xa0',\n",
       " b'\\xe5',\n",
       " b'\\xa5',\n",
       " b'\\xbd']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"hello, 你好\".encode(\"utf-8\")\n",
    "[bytes([b]) for b in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2713459a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b'\\xe4\\xbd\\xa0').decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e6159",
   "metadata": {},
   "source": [
    "### 2.3 Subword Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb7babd",
   "metadata": {},
   "source": [
    "### 2.4 BPE Tokenizer Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1290735e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['some', ' text', ' that', ' i', \"'ll\", ' pre', '-', 'tokenize']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(PAT, \"some text that i'll pre-tokenize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1de4c71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BA', 'A')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"ZZ\"), (\"BA\", \"A\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1afabb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"\"\"low low low low low lower lower widest widest widest newest newest newest newest newest newest\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f73644c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['low',\n",
       " ' low',\n",
       " ' low',\n",
       " ' low',\n",
       " ' low',\n",
       " ' lower',\n",
       " ' lower',\n",
       " ' widest',\n",
       " ' widest',\n",
       " ' widest',\n",
       " ' newest',\n",
       " ' newest',\n",
       " ' newest',\n",
       " ' newest',\n",
       " ' newest',\n",
       " ' newest']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(PAT, test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f545de",
   "metadata": {},
   "source": [
    "### 2.5 Experimenting with BPE Tokenizer Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71344ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"abere erererere<|endoftext|>When and where is not as important as who and what. Hi, I am the the Ivan.<|endoftext|> aaa\"\n",
    "input_path: str = \"\"\n",
    "vocab_size: int = 260\n",
    "special_tokens: list[str] = ['<|endoftext|>']\n",
    "\n",
    "vocab: dict[int, bytes] = {i:bytes([i]) for i in range(256)}\n",
    "vocab_inverse: dict[int, bytes] = {v:k for k,v in vocab.items()}\n",
    "merges: list[tuple[bytes, bytes]] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d83e3bd",
   "metadata": {},
   "source": [
    "- [x] vocab\n",
    "- [x] vocab_inverse \n",
    "- [x] merges \n",
    "- [x] pair_freqs\n",
    "- [x] pair_to_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610a05f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1611cd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abere erererere'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_pat = \"|\".join(re.escape(st) for st in special_tokens)\n",
    "segments = re.split(special_pat, test_string)\n",
    "text_segment = segments[0]\n",
    "matches = re.finditer(PAT, text_segment)\n",
    "word_freqs = defaultdict(int)\n",
    "pair_freqs = defaultdict(int)\n",
    "pair_to_tokens = defaultdict(set)\n",
    "text_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11333c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {(b'a', b'b'): 1,\n",
       "             (b'b', b'e'): 1,\n",
       "             (b'e', b'r'): 5,\n",
       "             (b'r', b'e'): 5,\n",
       "             (b' ', b'e'): 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for match in matches:\n",
    "    token = match.group()\n",
    "    token_bytes = token.encode(\"utf-8\")\n",
    "    word_freqs[token_bytes] += 1\n",
    "    if len(token_bytes)>1:\n",
    "        for i in range(1, len(token_bytes)):\n",
    "            pair = (bytes([token_bytes[i-1]]), bytes([token_bytes[i]]))\n",
    "            pair_freqs[pair] += 1\n",
    "            pair_to_tokens[pair].add(token_bytes)\n",
    "pair_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7feb0034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'r', b'e')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### find most frequent pair\n",
    "best_pair = max(pair_freqs.keys(), key=lambda k: (pair_freqs[k], k))\n",
    "vocab[new_id] = best_pair\n",
    "vocab_inverse[best_pair] = new_id\n",
    "merges.append(best_pair)\n",
    "best_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b49b7746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'abere'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affected_tokens = pair_to_tokens[best_pair]\n",
    "merged_bytes = best_pair[0] + best_pair[1]\n",
    "\n",
    "token = (next(iter(affected_tokens)))\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57431f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b're'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3521672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_neighbors = []\n",
    "i=0\n",
    "duplications_count = 0\n",
    "new_token = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ee4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "98\n",
      "98\n",
      "101\n",
      "101\n",
      "114\n",
      "114\n",
      "101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[97, 98, 101, 114]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while(i<(len(token)-1)):\n",
    "    print(token[i])\n",
    "    print(token[i+1])\n",
    "    if (bytes([token[i]]) == best_pair[0]) and (bytes([token[i+1]]) == best_pair[1]):\n",
    "        print('yes')\n",
    "        new_token.append(merged_bytes)\n",
    "        i = i + 2\n",
    "        duplications_count += 1\n",
    "    else:\n",
    "        new_token.append(bytes([token[i]]))\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9710eea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'abere'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d4118cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'r', b'e')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bc7a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "## update pair_freqs and pair_to_tokens\n",
    "affected_tokens = pair_to_tokens[best_pair]\n",
    "merged_bytes = best_pair[0]+best_pair[1]\n",
    "for token in affected_tokens:\n",
    "    new_neighbors = []\n",
    "    i=0\n",
    "    duplications_count = 0\n",
    "    while(i<len(token)-len(merged_bytes)+1):\n",
    "        if token[i:(i+len(merged_bytes))] == merged_bytes:\n",
    "            duplications_count += 1\n",
    "            if i != 0:\n",
    "                new_neighbors.append((bytes([token[i-1]]), merged_bytes))\n",
    "            if i + len(merged_bytes) != len(token):\n",
    "                new_neighbors.append((merged_bytes, bytes([token[i + len(merged_bytes)]])))\n",
    "            i += len(merged_bytes)\n",
    "        else:\n",
    "            i += 1\n",
    "    pair_freqs[best_pair] -= duplications_count*word_freqs[token]\n",
    "    for pair in new_neighbors:\n",
    "        pair_freqs[pair] += word_freqs[token]\n",
    "        pair_to_tokens[pair].add(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948772ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {(b'a', b'b'): 1,\n",
       "             (b'b', b'e'): 1,\n",
       "             (b'e', b'r'): 5,\n",
       "             (b'r', b'e'): 0,\n",
       "             (b' ', b'e'): 1,\n",
       "             (b'e', b're'): 5,\n",
       "             (b're', b'r'): 3})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5174d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b' erererere', b'abere'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affected_token = next(iter(affected_tokens))\n",
    "\n",
    "duplications_count = 0\n",
    "while(i<len(affected_token)-len(merged_bytes)+1):\n",
    "    print(i)\n",
    "    if affected_token[i:(i+len(merged_bytes))] == merged_bytes:\n",
    "        duplications_count += 1\n",
    "        if i != 0:\n",
    "            new_neighbors.append((bytes([affected_token[i-1]]), merged_bytes))\n",
    "        if i + len(merged_bytes) != len(affected_token):\n",
    "            new_neighbors.append((merged_bytes, bytes([affected_token[i + len(merged_bytes)]])))\n",
    "        i += len(merged_bytes)\n",
    "    else:\n",
    "        i += 1\n",
    "new_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f82a057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplications_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_freqs[best_pair] -= duplications_count*word_freqs[affected_token]\n",
    "for pair in new_neighbors:\n",
    "    pair_freqs[pair] += word_freqs[affected_token]\n",
    "    pair_to_tokens[pair].add(affected_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e522893e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {(b'a', b'b'): {b'abere'},\n",
       "             (b'b', b'e'): {b'abere'},\n",
       "             (b'e', b'r'): {b' erererere', b'abere'},\n",
       "             (b'r', b'e'): {b' erererere', b'abere'},\n",
       "             (b' ', b'e'): {b' erererere'},\n",
       "             (b'e', b're'): {b' erererere'},\n",
       "             (b're', b'r'): {b' erererere'}})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_to_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c197d5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {(b'a', b'b'): 1,\n",
       "             (b'b', b'e'): 1,\n",
       "             (b'e', b'r'): 5,\n",
       "             (b'r', b'e'): 1,\n",
       "             (b' ', b'e'): 1,\n",
       "             (b'e', b're'): 4,\n",
       "             (b're', b'r'): 3})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfa760e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
